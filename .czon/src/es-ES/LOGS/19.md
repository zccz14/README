---
"title": "Reflexión sobre la experiencia de desarrollo con IA: Limitaciones y direcciones de mejora de los LLM desde la construcción de CZONE"
"summary": "Este artículo documenta la experiencia del autor el 19 de enero de 2026 al construir desde cero una versión en línea de CZON (CZONE) utilizando OpenCode y MiniMax M2.1. La IA fue muy rápida en la selección tecnológica, configuración del scaffolding y diseño de funcionalidades, pero mostró una comprensión insuficiente de los detalles al manejar problemas de permisos de la API REST de GitHub, especialmente al no identificar los requisitos de permisos especiales para el directorio `.github/workflows`. El autor señala que los LLM presentan problemas de atención dispersa y capacidad de razonamiento débil en modo depuración, y sugiere introducir un \"modo laboratorio\" para realizar experimentos de control y verificación. Además, OpenCode carece de capacidad para controlar el navegador, lo que hace que la depuración dependa de la revisión manual de registros; el autor recomienda integrar marcos de pruebas de extremo a extremo como Cypress o Playwright. Asimismo, el ritmo de desarrollo de la IA es demasiado rápido, carece de arquitectura por capas y garantía de calidad; el autor lo compara con \"agua que se desborda\", enfatizando la necesidad de conceptos, abstracciones e implementaciones correctos. El artículo concluye con una analogía de un fontanero reparando una fuga, sugiriendo que el desarrollo con IA requiere soluciones sistémicas a problemas fundamentales en lugar de parches temporales."
"tags":
  - "Desarrollo con IA"
  - "Limitaciones de LLM"
  - "OpenCode"
  - "Capacidad de depuración"
  - "API de GitHub"
  - "Gestión de permisos"
  - "Ritmo de desarrollo"
  - "Modo laboratorio"
"date": "2026-01-19"
---

Ahora es la tarde del lunes 19 de enero de 2026.

Hoy me levanté muy tarde porque anoche estaba bastante emocionado trasteando con CZONE y OpenCode. Aunque el resultado no fue satisfactorio, si no lo hubiera intentado, quizás el resultado de ayer habría sido aún más fallido.

> Trasnochar es negarse a admitir el fracaso del día.
> — de PH

Anoche, utilicé OpenCode + MiniMax M2.1 para construir desde cero CZONE (la versión en línea de CZON), como se describe en [este registro](./18.md).

La IA comenzó preguntando y preguntando, desde la selección tecnológica hasta la configuración del scaffolding, pasando por el diseño de funcionalidades y finalmente el flujo de CI/CD. Todo el proceso fue muy rápido.

Sinceramente, fue un poco *demasiado* rápido, me sentí un poco mareado (risas).

Pero, y este es un gran pero, pronto surgieron problemas.

Descubrí que, al resolver problemas de permisos de la API REST de GitHub, su comprensión de los detalles era insuficiente.

**¿Memoria enciclopédica? No tanto.**

Por ejemplo, después de inicializar el repositorio, necesitábamos modificar el archivo `.github/workflows/pages.yml` para agregar los pasos de construcción de CZON. Esto requiere permisos de alcance (`scope`) `workflow`, pero el código proporcionado por OpenCode no incluía este permiso. Esto se puede ver fácilmente revisando la documentación de la API de GitHub. Sin embargo, ignoró repetidamente este detalle. Además, GitHub también es un poco tonto, el mensaje de error es solo un 404, sin ninguna indicación de permisos insuficientes. Y la IA tampoco se dio cuenta de este problema.

Durante este proceso, demostramos que escribir en `index.md` tuvo éxito, escribir en `.github/index.md` tuvo éxito, escribir en `github/workflows/pages.yml` también tuvo éxito, pero *solo* falló al escribir en `.github/workflows/pages.yml`. Aunque la conversación tuvo varias rondas (porque cada vez tenía que modificar un poco el código), algo tan evidente no hizo que se diera cuenta de que `.github/workflows/` podría ser un directorio con permisos especiales. Esto indica que su atención es dispersa y su capacidad de razonamiento (`Reasoning`) en modo depuración no es lo suficientemente fuerte.

Recomiendo encarecidamente que los LLM en sí mismos o un marco de control externo (`Agent`) tengan un **modo laboratorio** (`Lab Mode`). En este modo, el `Agent` debe diseñar repetidamente experimentos de control, verificar los resultados y así encontrar la verdad. A veces siento que un LLM es un cerebro inconsciente; iluminas donde tocas. Lo que dice el `prompt` es en lo que se enfoca.

A veces queremos que tenga una memoria enciclopédica, y otras veces deseamos que sea ignorante hasta la transparencia. En cierto sentido, la energía que consume un LLM es limitada; esperamos que, al enfrentar diferentes tareas, pueda asignar esa energía donde más se necesita, no distribuirla por igual. Algunos avances recientes en el campo de los LLM también suelen adoptar este enfoque.

**Cerebro en una cubeta, capacidad de acción limitada**

Otra razón importante y molesta es la capacidad de autodepuración insuficiente de OpenCode. Carece por completo de la capacidad de abrir y controlar un navegador (`Browser`), por lo que solo puede adivinar frecuentemente, registrar logs y pedirme que los revise. A veces juego con él, pero otras veces, mirándolo, es como mirar a mi `mentee`: no tengo idea de lo que está pensando, solo me desespero. Puedo aceptar tener un `mentee` un poco torpe, pero probablemente no pueda aceptar que sea un "cerebro en una cubeta sin manos": aún debemos encontrar la manera de completar el ciclo de su pensamiento. El `Antigravity` de Google, al otro lado, lo hace bastante bien, probablemente también por la cercanía con Chrome.

En cuanto a las soluciones comunitarias, usar marcos de pruebas de extremo a extremo (como Cypress o Playwright) para controlar el navegador debería ser una buena opción. Después de todo, muchas operaciones actuales requieren interacción del lado del cliente (`browser`); solo con APIs no es suficiente.

**Progreso demasiado rápido, fundamentos inestables**

La última razón que atribuyo es esta. Esta vez, la IA, partiendo de cero, en menos de 10 minutos me escribió docenas de archivos. La veía como una impresora, sin ninguna sensación de pausa o descanso. Sin embargo, cualquier sistema complejo necesita arquitectura, necesita capas, necesita garantizar la calidad básica de cada módulo. Solo después de hacer la capa inferior y realizar las pruebas, puedes proceder con confianza a las capas superiores. La IA actualmente carece por completo de este sentido del ritmo; simplemente imprime código. Aunque, si tuviera capacidad de depuración integrada, quizás podría modificar flexiblemente arriba y abajo, pero lo que realmente evita problemas depende fundamentalmente de conceptos correctos, abstracciones correctas, implementaciones correctas; depende de la coherencia lógica, de que tenga sentido. En cuanto al tiempo que la IA dedicaría a esto, creo que actualmente está muy lejos. Quizás esto es algo que solo puede resolver una capa de coordinación, no el LLM por sí mismo. **El LLM solo se encarga de abrir camino, como agua que se desborda, vertiéndose hacia el punto de menor energía potencial.**

![Depurar es como...](https://media.tenor.com/97gs87bOyQAAAAAM/debugging-programming.gif)

Pero muchos humanos también son así. El clásico chiste de antes: un fontanero repara una fuga, tapa un lugar y explota otro. Tratar el dolor de cabeza cuando duele la cabeza, el dolor de pie cuando duele el pie. Al final, el problema fundamental no se resuelve, y solo queda remar en el agua.