---
"title": "Discusión sobre la Observabilidad y los Métodos de Ingeniería en la Generación de Código por LLM"
"summary": "Este artículo documenta la discusión del autor con Hobo sobre la aplicación del código generado por LLM en entornos de producción. Los puntos clave incluyen: el código generado por LLM no puede usarse directamente en producción, debe garantizarse mediante pruebas rigurosas y observabilidad; la observabilidad requiere puntos de instrumentación intrusivos, aislamiento de recursos y sistemas de alerta, se sugiere incrustar las reglas de alerta en el código; el autor y Hobo difieren en la importancia de la inteligencia del LLM versus los métodos de ingeniería. El autor considera que los métodos de ingeniería (como las cadenas de prompts, los flujos de prueba) son más cruciales en la etapa actual, mientras que Hobo enfatiza el papel fundamental de la inteligencia del modelo. Ambas perspectivas son complementarias y valiosas para el equipo."
"tags":
  - "LLM"
  - "Observabilidad"
  - "Generación de Código"
  - "Métodos de Ingeniería"
  - "Inteligencia Artificial"
  - "Entorno de Producción"
  - "Pruebas"
"date": "2026-01-11"
---

Ahora es 11 de enero de 2026, domingo, madrugada.

Ayer almorcé con Hobo. Después de mucho tiempo sin vernos, hablamos de muchas cosas en la mesa. Él mostró un gran interés por nuestra situación actual y nuestro trabajo. Intercambiamos muchas ideas.

Envidio que él, trabajando en una empresa extranjera, pueda usar sin límites LLMs como GPT y Claude Opus para asistir en su trabajo y mejorar la eficiencia. En contraste, en nuestro entorno laboral en China, todavía existen muchas restricciones e inconvenientes para usar estas herramientas.

Nuestro consenso es que, en el trabajo de codificación actual, el código escrito por un LLM **no puede** ir directamente a un entorno de producción. Es muy, muy poco fiable.

### Observabilidad

Le pregunté: si nos limitamos a un módulo, y este pasa pruebas unitarias y de rendimiento (benchmark) rigurosas, ¿podría usarse? Él añadió que también se necesita una **observabilidad muy buena**, ya que hay que considerar la estabilidad del servicio a largo plazo (long-run).
Además, el costo de dividir un sistema enorme en muchos módulos pequeños tan bien definidos es en sí mismo muy alto.

Este es realmente un problema que había pasado por alto antes. En [este artículo](../INSIGHTS/1.md) mencioné que, después de pasar las pruebas de estilo de interfaz, las pruebas unitarias y las de rendimiento, uno puede confiar en el código generado por el LLM.
Una vez construí una prueba de rendimiento que consideraba el uso de CPU y memoria. Solo con pruebas de rendimiento ordinarias, no era posible detectar problemas de rendimiento en el código generado por el LLM. Tenías que aplicar pruebas de estrés de antemano para descubrir los problemas.
Las pruebas de estrés tampoco pueden simular realmente los diversos escenarios complejos de un entorno de producción, así que al final se necesita una **observabilidad muy buena** para poder usar el código generado por LLM en producción.

Pero, ¿cómo se deben diseñar y probar los sistemas de observabilidad?

La observabilidad en sí misma es también una herramienta para probar si la situación real cumple con las expectativas, solo que su entorno de ejecución es el de producción, no el de pruebas.

Además, puede necesitar ser **intrusiva** en el código de implementación para recopilar suficiente información. (La instrumentación intrusiva generalmente implica mayores costos de mantenimiento).

Si simplemente recopilamos algunas métricas externas a la interfaz y del entorno, a menudo solo podremos detectar una parte de los problemas.
Por ejemplo, no podremos observar si el estado interno del módulo es correcto, si está consumiendo demasiados recursos, si tiene fugas de memoria, si hay interbloqueos (deadlocks), etc.

Y las métricas de observabilidad a menudo están relacionadas con el **aislamiento de recursos**, como CPU, memoria, E/S, etc. Sin un muy buen aislamiento de recursos, a menudo es difícil detectar problemas.

Además, la clave de la observabilidad está en el **sistema de alertas**. Hobo mencionó una vez: "Cada punto de instrumentación (métrica) implica que debería tener una regla de alerta correspondiente; de lo contrario, ese punto de instrumentación no tiene sentido".

En la práctica habitual, las reglas de alerta son trabajo de operaciones (Ops), pero la instrumentación es trabajo de desarrollo. Quizás esta práctica en sí misma sea problemática. ¿Por qué no consideramos incrustar directamente las reglas de alerta en el código?

Por ejemplo, cada punto de instrumentación podría llevar una definición de regla de alerta. Cuando una métrica supere un cierto umbral, se activaría automáticamente una alerta. De esta manera, los desarrolladores, al escribir el código, podrían considerar directamente la observabilidad y las reglas de alerta, mejorando así la calidad y fiabilidad del código.

Por ejemplo, al instrumentar, también se podría diseñar un mecanismo de aserción (assert). Si la aserción no pasa, se activa una alerta. Esto se parece mucho al mecanismo de error/advertencia (error/warning). ¿Registrar un error o una advertencia en los logs significa automáticamente que necesita atención?

Podríamos empezar por los logs, registrando especialmente los logs de error y advertencia, usando estos logs como parte de la observabilidad y combinándolos con el sistema de alertas para mejorar la fiabilidad del sistema.

Estoy totalmente de acuerdo con el punto de Hobo: el código que va a producción **debe** tener una observabilidad muy buena; de lo contrario, no se puede garantizar la estabilidad a largo plazo (long-run).

### Nivel de Inteligencia del LLM vs. Métodos de Ingeniería

Además, Hobo mencionó el problema de la influencia del nivel de inteligencia propio del LLM en la calidad del código. Aquí tenemos algunas diferencias.

Él cree que el nivel de inteligencia del LLM es el factor clave que determina la calidad del código. Si el nivel de inteligencia es insuficiente, no puede completar la tarea.
Yo creo que, aunque el nivel de inteligencia del LLM es importante, lo más crucial es cómo diseñar bien la tarea y el flujo de pruebas para asegurar que el código generado cumpla con las expectativas.

Hobo se inclina por la capacidad de élite, es una perspectiva **innatista**; mientras que yo me inclino más por la optimización sistémica, una perspectiva **constructivista**.

Ambas tienen razón, pero en etapas diferentes.

-   **Por debajo del punto crítico de capacidad del modelo, yo tengo razón absoluta.** Para la gran mayoría de aplicaciones comerciales actuales, el valor de los métodos de ingeniería es mucho mayor que esperar al siguiente modelo "más inteligente". Una cadena de prompts (prompt chain) cuidadosamente diseñada, un conjunto de pruebas completo y un proceso iterativo pueden hacer que un modelo de capacidad media produzca código estable y utilizable. Este es el camino principal y exitoso para la implementación de aplicaciones de IA en la actualidad.

-   **Al enfrentar verdaderos límites cognitivos, la perspectiva de Hobo se hace evidente.** Cuando la complejidad de la tarea alcanza un nivel que requiere una verdadera comprensión, abstracción e innovación (por ejemplo, diseñar un algoritmo completamente nuevo, o entender un requisito extremadamente ambiguo y contradictorio), el "techo cognitivo" del modelo se convierte en un obstáculo insuperable. En ese momento, ni el mejor proceso puede hacer que el modelo complete algo que "cognitivamente no puede hacer".

Yo represento la **"pragmática del ingeniero"**, el motor central que hace que la IA cree valor en el presente.
Hobo representa la **"visión del investigador"**, enfocándose en los puntos de ruptura de las capacidades futuras.

El estado ideal sería **"inteligencia de élite" más "métodos de ingeniería de élite"**.

Usar el mejor proceso para estimular y aprovechar la inteligencia más poderosa. Nuestra diferencia no es sobre quién tiene razón o no, sino sobre el enfoque (optimización actual vs. avance fundamental) y la escala de tiempo (implementación a corto plazo vs. evolución a largo plazo).

En un equipo, esta perspectiva complementaria es muy valiosa.