Ahora es jueves, 29 de enero de 2026, al mediod칤a.

He ajustado mi horario y ahora me levanto por la ma침ana.

Ayer habl칠 con C1 sobre la funci칩n RFC [^1] de LegionMind. Mencion칩:

> Ahora que hemos dividido los m칩dulos, el trabajo en general se ha vuelto m치s lento, lo que hace que la alineaci칩n temprana de la documentaci칩n sea m치s importante.
>
> Es un poco como si, al aumentar el costo y el esfuerzo de implementaci칩n, nos acerc치ramos a un modelo de desarrollo en cascada.
>
> 쮼xiste un modelo 치gil adecuado para la velocidad de trabajo de la IA? Ese ser칤a definitivamente un 치gil aut칩nomo de la IA.
>
> Proporcionar a la IA hechos, permitirle comprender correctamente los **hechos** y la **intenci칩n** se vuelve m치s importante, para poder generar revisiones efectivas en las etapas intermedias e iteraciones 치giles.

[^1]: S칤. Es el est치ndar RFC (Request for Comments, Solicitud de Comentarios) del IETF. En la [Arquitectura de Ingenier칤a de Software con Colaboraci칩n Humano-M치quina a Nivel de M칩dulo](../INSIGHTS/1.md) mencionamos la Especificaci칩n del Protocolo, la nombramos RFC. Porque su funci칩n es muy similar a la de un RFC. Esperamos que la IA pueda usar el estilo RFC para describir su funcionalidad e interfaces.

Mi comentario al respecto es:

La autonom칤a de la IA es correcta. Porque el costo de la intervenci칩n humana es demasiado alto. Pero, 쯖칩mo puede ser aut칩noma la IA? El n칰cleo est치 en la alineaci칩n de la visi칩n cient칤fica.

## El n칰cleo de la autonom칤a de la IA es la alineaci칩n de la visi칩n cient칤fica

**El n칰cleo de la autonom칤a de la IA radica en la alineaci칩n de la visi칩n cient칤fica**. Es decir, la IA necesita comprender y seguir los conceptos y metodolog칤as cient칤ficas humanas.

La intenci칩n humana a veces es vaga, cambiante y no medible de antemano. Exigir a los humanos que alineen cada detalle de su intenci칩n con la IA antes de que se obtengan los resultados experimentales suele ser in칰til. En la expresi칩n inicial humana, solo la expresi칩n de valores es relativamente estable; otros detalles de la intenci칩n a menudo necesitan ajustes y optimizaciones continuas durante el proceso experimental.

Sin embargo, la IA a칰n puede hacer algunos esfuerzos para alinearse con la visi칩n cient칤fica b치sica humana.

Por ejemplo, la Navaja de Ockham (Occam's Razor): "Las entidades no deben multiplicarse innecesariamente" (Entities should not be multiplied beyond necessity). Este es un m칠todo heur칤stico muy utilizado en la comunidad cient칤fica. La IA puede adoptar este principio para optimizar los RFC.

Al generar un RFC, la IA a menudo agrega muchas funciones que parecen buenas pero poco pr치cticas. Esto aumenta la complejidad y el costo de implementaci칩n. Estoy seguro de que los lectores que han usado el modo PLAN lo han experimentado. Por ejemplo, agregar mecanismos complejos de manejo de errores en funciones simples, dise침ar planes de iteraci칩n de hasta 6 meses o introducir pilas tecnol칩gicas innecesarias.

Por lo tanto, la IA necesita aprender a simplificar sus objetivos, evitando el sobre-dise침o y la complejidad excesiva. Al adoptar la Navaja de Ockham, la IA puede gestionar sus objetivos de manera m치s efectiva, logrando as칤 una autonom칤a m치s eficiente.

La IA deber칤a usar una **arquitectura generativa adversarial** para manejar la tarea de generar RFCs. El revisor de RFCs de IA necesita se침alar cada punto de dise침o en el RFC, cuestionando a la IA generadora de RFCs y pidi칠ndole que explique por qu칠 es necesario ese punto de dise침o. **Si la necesidad de un punto de dise침o no puede justificarse razonablemente, entonces debe eliminarse.** Y la IA generadora de RFCs necesita respaldar sus decisiones de dise침o mediante **restricciones f치cticas**.

Las restricciones f치cticas provienen de informaci칩n f치ctica proporcionada por el Supervisor, obtenida a trav칠s de la exploraci칩n del entorno o adquirida desde bases de conocimiento externas. La IA necesita aprender a utilizar esta informaci칩n f치ctica para respaldar sus decisiones de dise침o. **Estos hechos deben ser verificables por terceros.**

La definici칩n de un hecho proviene del dise침o de un experimento verificable 游빍, y esto siempre ha sido la especialidad de la comunidad cient칤fica. La IA tambi칠n puede referenciar esta pr치ctica en ingenier칤a, dise침ando un c칩digo experimental. El plan experimental es el c칩digo en s칤, y los resultados del experimento pueden demostrar la veracidad del hecho. Cualquiera, incluidos humanos y revisores de RFCs, puede ejecutar este experimento para verificar el hecho.