---
"title": "Reflexiones sobre el Diseño de Arquitectura de Ingeniería de Software a Nivel de Módulo para Agentes de IA"
"summary": "Este artículo documenta las reflexiones del autor el 12 de enero de 2026 sobre la aplicación de Agentes de IA en la ingeniería de software a nivel de módulo. El autor propone una arquitectura de colaboración humano-máquina, cuyos puntos clave incluyen el uso de `git worktree` para gestionar repositorios de código, la invocación de Agentes de IA (como Claude Code) a través de CLI y la gestión de sesiones, la obtención de notificaciones de finalización del Agente y el historial de conversaciones para lograr transparencia. El autor planea implementar un script automatizado que asigne cada tarea a una sesión de Agente independiente y coordine el flujo de trabajo mediante un planificador. El artículo enfatiza la ventaja de usar Agentes en lugar de invocar directamente la API de un LLM: el Agente maneja la complejidad subyacente (como explorar el repositorio de código, invocar comandos del sistema, gestionar el contexto), evitando reinventar la rueda. El autor pretende implementar primero una versión simplificada para validar la idea."
"tags":
  - "Agente de IA"
  - "Ingeniería de Software"
  - "Colaboración Humano-Máquina"
  - "Claude Code"
  - "Automatización"
  - "Modularidad"
  - "Transparencia"
  - "Planificador"
"date": "2026-01-12"
---

Hoy es lunes, 12 de enero de 2026, por la mañana.

Me levanté temprano hoy y, recordando la discusión de ayer con C1 sobre el diseño de Agentes de IA, sentí que hubo algunas ideas inspiradoras que necesito anotar.

Consultando el [antecedente](czon://f14dd5dd9a733022055d249db9b1ed3d60d9b60b7eb8c063fe24c02774b6b631), diseñé una arquitectura de ingeniería de software a nivel de módulo para la colaboración humano-máquina.

Estoy considerando cómo implementarla.

En resumen, los puntos clave son:

1.  Es necesario usar el comando `git worktree` para gestionar el repositorio de código y proporcionar un script de configuración para cada Repo.
2.  Es necesario invocar al Agente de IA (Claude Code, OpenCode, ...etc) a través de la CLI, pasarle un prompt e iniciar una sesión (Session).
3.  Es necesario poder recibir una notificación de finalización del Agente de IA.
4.  Es necesario poder obtener el historial de conversaciones intermedias del Agente de IA; de lo contrario, no se puede lograr transparencia. Consultando el problema de confianza controlable mencionado en [este documento](czon://3a40b7b252512466f0b0feb8c7ea77fc624bb0026cbae8882c5c205462e0aa64), necesitamos transparencia y controlabilidad durante el proceso.

Basándome en estas capacidades, puedo implementar un script automatizado para completar tareas de ingeniería de software a nivel de módulo.

Tomando Claude Code como ejemplo:

1.  Claude Code puede recibir directamente un prompt a través de la CLI e iniciar una nueva sesión.
2.  Claude Code puede usar el parámetro `-p` para indicar el final cuando envía el resultado a la salida estándar (stdout).
3.  Claude Code proporciona la capacidad de pasar un ID de sesión, luego se puede buscar el archivo correspondiente del historial de conversaciones en el directorio `.claude` para obtener los mensajes históricos.

Dado esto, puedo escribir un script para gestionar este trabajo.

Cada Sesión es independiente y limpia; cada Sesión será asignada a un Agente para completarla.

Una instancia de Agente puede abstraerse como una interfaz, independientemente de si su implementación subyacente es Claude Code u otra.

Y el planificador coordinará diferentes Agentes para completar las tareas según nuestro flujo de trabajo predefinido.

¿Por qué basarse en un Agente y no en la API de un LLM? Porque el Agente maneja por nosotros la lógica subyacente de explorar el repositorio de código, invocar comandos del sistema operativo, gestionar el contexto y adaptarse a la API del LLM. Este es un sistema complejo, y creo que no necesitamos reinventar la rueda, a menos que no cumpla con los requisitos.

Planeo implementar primero una versión mínima para verificar si este enfoque es viable. Esperen los registros de progreso posteriores.