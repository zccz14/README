---
"title": "Diseño de Arquitectura de Ingeniería de Software con Colaboración Humano-Máquina a Nivel de Módulo"
"summary": "Este artículo aborda los problemas de baja calidad, límites poco claros y lentitud en la implementación de módulos de código por parte de los agentes de IA existentes, proponiendo una arquitectura de ingeniería de software con colaboración humano-máquina a nivel de módulo. La arquitectura garantiza la calidad de la implementación mediante colaboración por capas (incluyendo alineación de intenciones, generación de protocolos, implementación, pruebas, pruebas de referencia, etc.) y división profesional del trabajo, combinada con un mecanismo de arbitraje multinivel. Los objetivos principales son reducir la intervención humana, mejorar la velocidad de ejecución, disminuir los costos de LLM, y establecer un mecanismo de confianza mediante criterios de aceptación claros (como la aprobación de pruebas unitarias y la no degradación del rendimiento), eliminando el deseo de control humano. El artículo también discute problemas no resueltos (como la calidad del protocolo y el control de ciclos de arbitraje) y perspectivas futuras (como reemplazar la supervisión humana con IA más avanzada)."
"tags":
  - "Colaboración Humano-Máquina"
  - "Ingeniería de Software"
  - "LLM"
  - "Agente de IA"
  - "Diseño de Módulos"
  - "Mecanismo de Arbitraje"
  - "Automatización"
---

# Arquitectura de Ingeniería de Software con Colaboración Humano-Máquina a Nivel de Módulo

## Contexto del Problema

Diseñar una arquitectura de ingeniería para colaboración humano-máquina a nivel de módulo utilizando LLM, con el objetivo de completar de manera eficiente el diseño, implementación e iteración de módulos de aplicaciones de nivel industrial, reduciendo los costos de intervención humana.

1. Los agentes de IA existentes (Claude Code, CodeX) tienen una calidad muy baja en la implementación de módulos de código, aún requiriendo una alta intervención, reelaboración y revisión humana.
2. Los agentes de IA existentes tienen dificultades para definir los límites de los módulos durante la implementación, lo que resulta en la escritura de código con complejidad innecesaria.
3. La implementación con los agentes de IA existentes es demasiado lenta, tomando de 10 a 30 minutos desde la asignación de una tarea hasta su aceptación.

## Perspectiva del Problema

- Según [este artículo](czon://b283a1863e9af777d581f5af32c0d2d27ed22194f391f5bc3cef9d0d445b4e8c), el deseo de control humano surge de preocupaciones racionales sobre la pérdida de control sobre las consecuencias; establecer un mecanismo de confianza controlable es la solución.
- Según [este artículo](czon://2b0a022c6abba013f5f8dcf8f24e4cd0662b3db73ff017c3bb8799d0541537ae), creo que los mecanismos físicos y económicos de los LLM determinan que es difícil que completen todo el trabajo de una sola vez.

Para liberar la productividad humana, la clave es eliminar el deseo humano de controlar los detalles; entonces, las personas adoptarán una mentalidad de "si funciona, sirve" y dejarán de exigir más del trabajo de la IA.

Entonces, ¿qué verificaciones deben pasar para que una persona juzgue que ya no tiene la capacidad de intervenir o que no es necesario tomar más medidas?

1. El estilo de nomenclatura de los conceptos de interfaz externa del módulo cumple con los requisitos. Esto elimina la preocupación de que interfaces irrazonables se propaguen a las partes posteriores del sistema.
2. Aprobación de las pruebas unitarias. Esto elimina la preocupación sobre si el módulo funcionará correctamente.
3. Optimización o no degradación en las pruebas de referencia. Esto elimina la preocupación sobre si el módulo será ineficiente.
   El primer punto se puede detectar en la fase inicial, mientras que los otros dos solo se conocen al final del experimento. Si se cumplen los tres, los humanos no tienen razones para intervenir forzosamente en el trabajo completado por la IA.

En cuanto a si este módulo realmente puede manejar patrones de datos reales, se deben usar datos del entorno de producción para probarlo. Luego, una persona resume sus patrones y construye un nuevo módulo a través de la intención para resolver nuevos problemas. Este tema no está dentro del alcance de este artículo por ahora.

### Objetivos Prioritarios

1. Reducir la intervención humana.
2. Reducir el tiempo de ejecución, mejorar la velocidad.
3. Reducir el uso de tokens, disminuir los costos de LLM.

### Diseño

```mermaid
graph TD

   subgraph Agent
   A_1[Especificación del Protocolo]
   A_1 --> A_2[Código del Protocolo]
   A_1 --> A_A[Especificación de Implementación]
   A_1 --> A_B[Especificación de Pruebas]
   A_1 --> A_C[Especificación de Referencia]
   A_A --> A_A_1[Código de Implementación]
   A_B --> A_B_1[Código de Pruebas]
   A_C --> A_C_1[Código de Referencia]
   A_A_1 --> A_D[Informe]
   A_B_1 --> A_D
   A_C_1 --> A_D
   end

   subgraph Human
   H_1[Intención] -->|Asignar| A_1
   A_D -->|Revisar| H_1
   end

```

1. **Alineación Rápida de Intenciones**

   El humano describe la intención para alinearse rápidamente con el Agente sobre los requisitos funcionales del módulo, generando la Especificación del Protocolo.

   La Especificación del Protocolo incluye la definición de interfaces, formatos de datos de entrada/salida, descripción funcional, etc., similar a un documento RFC. El humano debe centrarse en la definición de interfaces y la descripción funcional, asegurando límites claros del módulo, especialmente evaluando el estilo de las interfaces.

   Este proceso puede completarse mediante múltiples interacciones; el Agente modificará continuamente la Especificación del Protocolo según la retroalimentación humana hasta que sea aprobada.

   A continuación, habrá un largo proceso de implementación automatizada durante el cual el humano no necesita intervenir. Habrá dos resultados: 1. La implementación del módulo tiene éxito, generando un informe final para revisión humana; 2. La implementación del módulo falla, generando una solicitud de arbitraje para intervención humana.

2. **Generación de Código de Protocolo desde la Especificación del Protocolo**

   El Agente genera el código esqueleto del módulo (Código de Protocolo) basado en la Especificación del Protocolo, incluyendo definiciones de interfaces y comentarios.
   El Código de Protocolo se utilizará para la generación posterior de código de implementación, pruebas y referencia. Su objetivo principal es garantizar límites claros del módulo, evitando complejidad innecesaria durante la implementación.

3. **Generación Paralela de Especificaciones de Implementación, Pruebas y Referencia desde la Especificación del Protocolo**

   Se solicita a diferentes Agentes que generen la Especificación de Implementación, Especificación de Pruebas y Especificación de Referencia basándose en la Especificación del Protocolo, describiendo respectivamente los detalles de implementación, casos de prueba y planes de pruebas de referencia del módulo.

4. **Generación de Código de Pruebas desde la Especificación de Pruebas**

   Se solicita a un Agente especializado en pruebas que genere el código de pruebas unitarias del módulo (Código de Pruebas) basado en la Especificación del Protocolo y la Especificación de Pruebas, incluyendo diversos casos de prueba y aserciones. Es crucial utilizar métodos de prueba basados en interfaces para evitar acoplamiento con detalles de implementación.

5. **Generación de Código de Referencia desde la Especificación de Referencia**

   Se solicita a un Agente especializado en pruebas de referencia que genere el código de pruebas de referencia del módulo (Código de Referencia) basado en la Especificación del Protocolo y la Especificación de Referencia, incluyendo casos de prueba de rendimiento y métricas de medición. Es crucial utilizar métodos de prueba basados en interfaces para evitar acoplamiento con detalles de implementación.

6. **Generación de Código de Implementación desde la Especificación de Implementación**

   Se solicita a un Agente especializado en implementación que genere el código de implementación del módulo (Código de Implementación) basado en la Especificación del Protocolo, Especificación de Implementación, Especificación de Pruebas y Especificación de Referencia. Una vez completada la implementación, se ejecutan inmediatamente las pruebas unitarias.

   Si las pruebas unitarias no se aprueban, se analiza la causa del fallo.

   - Si se considera que el problema está en la Implementación, se modifica la Especificación de Implementación y se regenera el Código de Implementación. Se repite este proceso.
   - Si se considera que el problema está en las Pruebas, se recopilan los detalles del fallo de prueba y se integran en una objeción. Luego, se envía a un Agente de Arbitraje de nivel superior para su procesamiento.

     - Si la objeción es aceptada, el Agente de Arbitraje puede optar por modificar la Especificación de Pruebas y repetir las pruebas. Se repite este proceso.
     - Si la objeción es rechazada, el Agente de Arbitraje genera una explicación, solicitando al Agente de Implementación que modifique la Especificación de Implementación y repita el proceso de implementación. Se repite este proceso.
     - **Si el Agente de Arbitraje considera que no puede juzgar, solicitará la intervención humana para arbitrar.**

   Si las pruebas unitarias se aprueban, se procede a las pruebas de referencia.

7. **Ejecución de Pruebas de Referencia**

   El Código de Implementación que ha aprobado las pruebas unitarias puede ejecutar las pruebas de referencia.

   Si no existe otra versión de implementación comparable, se marca la implementación actual como versión de referencia, se ejecutan las pruebas de referencia, se registran las métricas de rendimiento y se aprueban las pruebas de referencia.

   Si existe otra versión de implementación comparable, se ejecutan las pruebas de referencia, se registran las métricas de rendimiento y se genera un informe comparativo para que el Agente analice los cambios de rendimiento de la versión actual.

   - Si el rendimiento de la versión actual se degrada, se analiza la causa.

     - Si se considera que el problema está en la Implementación, se modifica la Especificación de Implementación y se regenera el Código de Implementación. Se repite este proceso.

     - Si se considera que el problema está en la Referencia, se recopilan los detalles del fallo en las pruebas de referencia y se integran en una objeción. Luego, se envía a un Agente de Arbitraje de nivel superior para juzgar.

       - Si la objeción es aceptada, el Agente de Arbitraje puede optar por modificar la Especificación de Referencia y repetir las pruebas de referencia. Se repite este proceso. Si la objeción es rechazada, el Agente de Arbitraje declara que la tarea ha fallado y genera un informe final para revisión humana.
       - Si la objeción es rechazada, el Agente de Arbitraje devuelve la objeción al Agente de Implementación, solicitando que modifique la Especificación de Implementación y repita el proceso de implementación. Se repite este proceso.
       - **Si el Agente de Arbitraje considera que no puede juzgar, solicitará la intervención humana para arbitrar.**

   - Si el rendimiento de la versión actual no se degrada, se aprueban las pruebas de referencia.

8. **Generación del Informe Final**

   Una vez que el Código de Implementación aprueba las pruebas unitarias y de referencia, se genera un informe final que incluye detalles de implementación, resultados de pruebas y resultados de pruebas de referencia.
   El informe final se envía al humano para su revisión. Si el humano aprueba la implementación actual, la tarea se completa; de lo contrario, se recopila la retroalimentación humana y se integra en una objeción. Luego, se envía a un Agente de Arbitraje de nivel superior para su procesamiento. Si la objeción es aceptada, el Agente de Arbitraje puede optar por modificar la Especificación del Protocolo y repetir todo el proceso de implementación. Se repite este proceso.

## Resumen

1. El núcleo de la arquitectura es la colaboración por capas, división profesional del trabajo y separación de preocupaciones.
2. Mediante un mecanismo de arbitraje multinivel, se garantiza la calidad de la implementación y se reduce la intervención humana.
3. Criterios de aceptación claros (pruebas unitarias aprobadas, rendimiento no degradado) establecen un mecanismo de confianza, eliminando el deseo de control humano.

Aún hay problemas no resueltos:

1. ¿Cómo mejorar la calidad de la Especificación del Protocolo para garantizar límites claros del módulo? Añadir una fase de revisión automática.
2. ¿Cómo evitar ciclos infinitos de arbitraje? Por ejemplo, limitar el número máximo de arbitrajes automáticos.
3. ¿Cómo controlar el tiempo de ejecución real y la cantidad de tokens utilizados dentro de límites razonables? Medir primero, optimizar después.
4. ¿Cómo garantizar el estilo en el diseño de interfaces? Por ejemplo, incorporar una guía de estilo del equipo.

Algunas perspectivas:

1. ¿Por qué la posición humana debe ser humana? En realidad, es un Supervisor. ¿Podría usarse una IA de nivel superior en el futuro para reemplazar a los humanos en la alineación de intenciones y la revisión final? Esto reduciría aún más la intervención humana y mejoraría la eficiencia.
2. Si no son tareas a nivel de módulo, ¿podría extenderse a diseños e implementaciones de sistemas a mayor escala? Por ejemplo, tareas de desarrollo full-stack (frontend + backend + base de datos). Esto aumentaría enormemente el valor de la IA en el campo de la ingeniería de software.