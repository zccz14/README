---
"title": "LLM生成コードの可観測性とエンジニアリング手法に関する考察"
"summary": "本稿は、著者がHobo氏と行った、LLM生成コードの本番環境での活用に関する議論を記録したものです。主な論点は以下の通りです：LLMが生成したコードは本番環境に直接投入することはできず、厳格なテストと可観測性による保証が必要である。可観測性には、侵入型の計装、リソース分離、アラートシステムが必要であり、アラートルールをコードに埋め込むことを提案する。著者とHobo氏は、LLMの知能レベルとエンジニアリング手法の重要性について意見が分かれており、著者は現段階ではプロンプト連鎖やテストプロセスなどのエンジニアリング手法がより重要であると考え、Hobo氏はモデルの知能の根本的な役割を強調しています。両者の視点は補完的であり、チームにとって価値があるものです。"
"tags":
  - "LLM"
  - "可観測性"
  - "コード生成"
  - "エンジニアリング手法"
  - "人工知能"
  - "本番環境"
  - "テスト"
"date": "2026-01-11"
---

現在は 2026 年 1 月 11 日、日曜日、未明です。

昨日、久しぶりに Hobo と昼食を共にし、多くのことを話し合いました。彼は私たちの近況や仕事について非常に気にかけてくれていました。

外資系企業で働く彼が、GPT や Claude Opus などの LLM を無制限に使用して業務を補助し、効率を上げていることをとても羨ましく思います。それに比べ、私たちの国内での仕事環境では、これらのツールの使用にはまだ多くの制限や不便があります。

私たちの共通認識は、現在のコーディング作業において、LLM が書いたコードは本番環境に直接投入することは**非常に、非常に信頼できない**ということです。

### 可観測性

私は彼に尋ねました。「一つのモジュールに限定し、厳格な単体テストとベンチマークテストを通過した場合、使用できるでしょうか？」彼は補足しました。「それに加えて、非常に優れた可観測性が必要です。結局のところ、長期間にわたるサービスの安定性を考慮しなければなりませんから。さらに、巨大なシステムをそのような明確に定義された小さなモジュールに分割すること自体、非常にコストがかかります。」

これは確かに私が以前見落としていた問題です。[この記事](../INSIGHTS/1.md) で述べたように、インターフェーススタイルのテスト、単体テスト、ベンチマークテストを通過して初めて、人は LLM 生成コードを信頼できるようになります。
かつて、CPU とメモリ使用量を考慮したベンチマークテストを構築したことがありますが、通常のベンチマークテストだけでは、LLM 生成コードの性能問題を発見することはできませんでした。事前に負荷テストを行わなければ、問題を見つけることはできません。
負荷テストもまた、本番環境の様々な複雑なシナリオを真にシミュレートすることはできません。したがって、最終的には非常に優れた可観測性がなければ、本番環境で LLM 生成コードを使用することはできません。

しかし、可観測性はどのように設計し、テストすべきでしょうか？

可観測性自体も、実際の状況が期待通りであるかをテストするツールです。ただ、その実行環境がテスト環境ではなく、本番環境にあるという点が異なります。

さらに、十分な情報を収集するためには、実装コードに侵入する必要があるかもしれません。（侵入型の計装は通常、より高い保守コストを意味します）

インターフェースの外部や環境情報から単純にいくつかの指標データを収集するだけでは、問題の一部しか発見できないことがよくあります。
例えば、モジュール内部の状態が正しいか、過剰なリソースを占有していないか、メモリリークがないか、デッドロックがないかなどを観測することはできません。

また、可観測性の指標は、CPU、メモリ、I/O など、リソース分離と関係していることが多いです。非常に優れたリソース分離がなければ、問題を発見することは難しいでしょう。

そして、可観測性の鍵はアラートシステムにあります。Hobo はかつて、「すべての計装ポイントは、対応するアラートルールを持つべきであることを暗示しています。そうでなければ、その計装ポイントには意味がありません。」と述べていました。

通常の実践では、アラートルールは運用作業ですが、計装は開発作業です。おそらく、この実践自体に問題があるのかもしれません。なぜ、コードに直接アラートルールを埋め込むことを考えないのでしょうか？

例えば、各計装ポイントがアラートルールの定義を保持し、指標が特定の閾値を超えたときに自動的にアラートをトリガーするようにできます。これにより、開発者はコードを書く際に、直接可観測性とアラートルールを考慮に入れることができ、コードの品質と信頼性を向上させることができます。

例えば、計装と同時に、アサーション機構を設計することもできます。アサーションが通らなければ、アラートをトリガーします。これは error / warning 機構によく似ていますが、error / warning ログを記録することは、注目される必要があることを意味するのでしょうか？

まずはログから始めて、error / warning ログを重点的に記録し、これらのログを可観測性の一部として、アラートシステムと組み合わせて、システムの信頼性を向上させることもできます。

私は Hobo の見解に非常に同意します：本番環境に投入するコードは、非常に優れた可観測性を持っていなければならず、そうでなければ長期間の安定性を保証することはできません。

### LLM の知能レベル vs エンジニアリング手法

また、Hobo は、LLM 自体の知能レベルがコーディング品質に与える影響についても言及しました。ここで私たちの意見は分かれました。

彼は、LLM の知能レベルがコーディング品質を決定する重要な要素であり、知能レベルが不十分であればタスクを完了できないと考えています。
一方、私は、LLM の知能レベルも重要ですが、より重要なのは、タスクとテストプロセスを適切に設計し、生成されるコードが期待通りであることを確実にすることだと考えています。

Hobo はエリートの能力、つまり**天賦主義**的な見方を好みます。一方、私はシステム最適化、つまり**構築主義**的な見方を好みます。

どちらも正しいですが、段階が異なります。

- モデルの能力の臨界点以下の段階では、私の考えは絶対に正しいです。現在のほとんどの商業アプリケーションにとって、エンジニアリング手法の価値は、次の「より賢い」モデルを待つことよりもはるかに大きいです。注意深く設計されたプロンプト連鎖、完全なテストスイート、反復プロセスにより、能力が中程度のモデルでも安定した使用可能なコードを生成することが完全に可能です。これは現在、AI アプリケーションを実用化する主流かつ成功への道です。

- 真の認知的限界に直面したとき、Hobo の見解が現れます。タスクの複雑さが、真の理解、抽象化、革新を必要とするレベルに達したとき（例えば、全く新しいアルゴリズムを設計する、または極めて曖昧で矛盾する要求を理解する）、モデルの「知能の天井」は乗り越えられない障害となります。このとき、どんなに優れたプロセスでも、モデルが「認知的にできない」ことを完了させることはできません。

私が代表するのは「エンジニアの現実主義」であり、現在 AI に価値を創造させるための核心的な推進力です。
Hobo が代表するのは「研究者の先見性」であり、将来の能力の突破口に注目しています。

最も理想的な状態は、「エリートレベルの知能」に「エリートレベルのエンジニアリング手法」を組み合わせることです。

最良のプロセスを用いて、最も強力な知能を引き出し、制御することです。私たちの意見の相違は、正誤の問題ではなく、注目点（現在の最適化 vs 根本的な突破）と時間軸（短期間での実用化 vs 長期的な進化）の違いです。

チームにおいて、このような補完的な視点は非常に貴重です。