現在は2026年1月19日、月曜日の午後です。

今日はとても遅く起きました。昨夜、CZONEとOpenCodeのことで興奮して色々と試していたからです。結果は満足のいくものではありませんでしたが、もし試していなければ、昨日の結果はもっと失敗していたかもしれません。

> 徹夜は、一日の失敗を認めたくないという意思表示だ。
> —— from PH

昨夜、OpenCodeとMiniMax M2.1を使って、CZONE（オンライン版CZON）を一から構築してみました。詳細は[この日誌](./18.md)をご覧ください。

AIは、技術選定からスキャフォールディングの構築、機能設計、そしてCI/CDのワークフローまで、一連の質問を矢継ぎ早に投げかけ、プロセス全体が非常に速く進みました。

正直に言うと、少し速すぎて、私は少し「酔って」しまいました（笑）。

しかし、重要な「しかし」があります。すぐに問題にぶつかりました。

GitHub REST APIの権限問題を解決する際に、AIは細部の理解が不十分であることに気づきました。

**博識で記憶力が強い？そうではありません。**

例えば、リポジトリを初期化した後、`.github/workflows/pages.yml`ファイルを修正してCZONのビルドステップを追加する必要があります。これは`workflow`スコープの権限を必要とする作業ですが、OpenCodeが提供したコードにはこの権限が含まれていませんでした。これはGitHub APIのドキュメントを少し調べればわかることです。しかし、AIは繰り返しこの詳細を見落としていました。また、GitHubも馬鹿げていて、エラーメッセージは単なる404だけで、権限不足のヒントは全くありませんでした。AIもこの問題に全く気づいていませんでした。

この過程で、`index.md`への書き込みは成功し、`.github/index.md`への書き込みも成功し、`github/workflows/pages.yml`への書き込みも成功しましたが、`.github/workflows/pages.yml`だけが失敗しました。会話は何度もやり取りされましたが、AIは毎回コードを少しずつ変更するだけでした。これほど明白なのに、`.github/workflows/`ディレクトリが特別な権限を必要とする可能性があることに気づかなかったのです。これは、AIの注意力が散漫で、デバッグモードでの推論能力が十分でないことを示しています。

私は強く提案します。LLM自体、または外部の制御フレームワークであるエージェントには、**ラボモード**(Lab Mode)が必要です。このモードでは、エージェントは対照実験を繰り返し設計し、実験結果を検証して真実を見つけ出す必要があります。私は時々、LLMは無意識の脳のようなものだと思います。どこを指しても、そこだけが光ります。プロンプトが何を言うかによって、そこに注目します。

時には、私たちはAIに博識であってほしいと願い、時には、澄み切ったほどに無知であってほしいと願います。ある意味、LLMが消費するエネルギーは一定であり、私たちは、異なるタスクに対処する際に、エネルギーを最も必要な場所に分配してほしいと願っています。平均的に分配するのではなく。最近のLLM分野の進展も、しばしばこの考え方を採用しています。

**水槽の中の脳、行動力は限られている**

もう一つ、非常に重要で煩わしい理由は、OpenCodeの自己デバッグ能力が不十分なことです。ブラウザを開いて操作する能力が全くないため、頻繁に推測したり、ログを出力したりして、私にログを見てくれるよう頼むしかありません。私は時々それに付き合って遊びますが、時々AIを見ていると、まるで私のメンティーのようで、何を考えているのか全くわからず、ただやきもきします。私は少し不器用なメンティーを持つことは受け入れられますが、「両手のない」水槽の中の脳であることはおそらく受け入れられません。やはり、その思考を完結させる方法を考えなければなりません。隣のGoogle社のAntigravityはうまくやっているようです。Chromeと親戚関係にあるからかもしれません。

コミュニティのソリューションとしては、CypressやPlaywrightなどのエンドツーエンドテストフレームワークを使ってブラウザを操作することが良い選択肢でしょう。結局のところ、現在多くの操作はブラウザ側のインタラクションを必要としており、APIだけでは不十分です。

**進歩が速すぎて、基盤が不安定**

最後の理由は、私自身の帰属意識にもあります。今回、AIはゼロから始めて、10分もかからずに何十ものファイルを書き出しました。私はAIがまるで印刷機のように、全く休むことなく動いているのを見ました。しかし、どんな複雑なシステムも、アーキテクチャ、階層化、各モジュールの基礎的な品質保証が必要です。下層を構築し、テストを完了して初めて、上層を安心して構築できます。AIには今、このようなリズム感が全くありません。純粋にコードを印刷しているだけです。もし自己デバッグ能力が備わっていれば、柔軟に上下を変更できるかもしれませんが、本当に問題を起こさないためには、本質的には正しい概念、正しい抽象化、正しい実装に依存し、筋が通っていて、説明がつくものでなければなりません。AIがこのことにどれだけ時間を費やすかについては、現時点ではまだ遠く及ばないと思います。おそらく、これは調整層だけが解決できることであり、LLM単体ではできません。**LLMはただ道を切り開くだけです。洪水のように、位置エネルギーの最も低いところに流れ込んでいきます。**

![デバッグとは...](https://media.tenor.com/97gs87bOyQAAAAAM/debugging-programming.gif)

しかし、多くの人間も同じです。昔からの古典的なジョークがあります。配管工が水漏れを修理し、ここを塞げばあちらが破裂する。頭痛には頭を、足の痛みには足を治療する。結局根本的に解決できず、ただ水の中でボートを漕ぐしかないのです。