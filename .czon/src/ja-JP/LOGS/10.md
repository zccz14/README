今日は2026年1月12日、月曜日の朝です。

今朝は早起きをし、昨日C1と議論したAI Agentの設計問題を振り返り、いくつかの示唆を得たので、記録しておく必要があると感じました。

[前情提要](../INSIGHTS/1.md)を参照すると、私はモジュールレベルの人間とAIの協調によるソフトウェアエンジニアリングアーキテクチャを設計しました。

私はその実現方法を検討しています。

簡単に言えば、重要なポイントは以下の通りです：

1.  `git worktree` コマンドを使用してコードリポジトリを管理し、各リポジトリにセットアップスクリプトを用意する必要があります。
2.  CLIを通じてAI Agent (Claude Code, OpenCode, ...など) を呼び出し、プロンプトを渡してセッションを開始する必要があります。
3.  AI Agentからの終了通知を受け取れる必要があります。
4.  AI Agentの中間的な対話履歴を取得できる必要があります。そうでなければ透明性を達成できません。[このドキュメント](../INSIGHTS/2.md)で言及されている「制御可能な信頼性」問題を参照すると、我々にはプロセス中の透明性と制御性が必要です。

これらの機能に基づいて、モジュールレベルのソフトウェアエンジニアリングタスクを完了するための自動化スクリプトを実装できます。

Claude Codeを例にとると、

1.  Claude Codeは、CLIから直接プロンプトを渡すことで、新しいセッションを開始できます。
2.  Claude Codeは `-p` パラメータを使用して、結果を標準出力に出力する際に終了を識別できます。
3.  Claude CodeはセッションIDを渡す機能を提供しており、それに基づいて `.claude` ディレクトリ内の対応する対話履歴ファイルを見つけ、過去のメッセージを取得できます。

したがって、これらの作業を管理するスクリプトを書くことができます。

各セッションは独立しており、クリーンです。各セッションは、タスクを完了するために1つのAgentに割り当てられます。

Agentインスタンスは、その基盤がClaude Codeであろうと他のものであろうと関係なく、インターフェースとして抽象化できます。

スケジューラーは、事前に定義されたワークフローに基づいて、異なるAgentをスケジュールしてタスクを完了させます。

なぜLLM APIではなくAgentに基づくのでしょうか？それは、Agentがコードリポジトリの探索、オペレーティングシステムコマンドの呼び出し、コンテキスト管理、LLM APIへの適応といった基盤的なロジックを処理してくれるからです。これは複雑なシステムであり、要求を満たさない場合を除き、車輪の再発明は必要ないと考えています。

まずは最小限のバージョンを実装し、この考え方が実現可能かどうかを検証する予定です。今後の進捗記録にご期待ください。