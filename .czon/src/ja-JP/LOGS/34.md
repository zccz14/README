現在は2026年1月29日、木曜日、正午です。

生活リズムを調整して、朝型になりました。

昨日、C1とLegionMindのRFC[^1]機能について話し合いました。彼は次のように述べています：

> モジュール分割後、全体として作業が遅くなり、初期段階でのドキュメントの整合がより重要になりました。
>
> 実装コストと負担が大きくなったことで、ウォーターフォール開発モデルに近づいている感じです。
>
> AIの作業速度に適したアジャイルモデルはあるでしょうか？それは間違いなくAI自律型のアジャイルでしょう。
>
> AIに事実を与え、**事実**と**意図**を正しく理解させることがより重要になります。そうすれば、効果的な中間レビューとアジャイルな反復が可能になります。

[^1]: そうです。IETFのRFC（Request for Comments、コメント募集）標準のことです。[モジュールレベルでの人間-AI協調ソフトウェアエンジニアリングアーキテクチャ](../INSIGHTS/1.md)で言及されているProtocol Specを、私たちはRFCと名付けました。その機能とインターフェースがRFCと非常に類似しているためです。AIがRFCのスタイルでそれらの機能とインターフェースを記述することを期待しています。

これに対する私のコメントは以下の通りです：

AIの自律は正しい方向です。人間が介入するコストが高すぎるからです。しかし、AIはどのように自律すればよいのでしょうか？その核心は科学的視座の整合にあります。

## AI自律の核心は科学的視座の整合

**AI自律の核心は、科学的視座の整合にあります**。つまり、AIは人間の科学的な考え方と方法論を理解し、それに従う必要があります。

人間の意図は時に曖昧で、変化しやすく、事前に測定できないものです。実験結果が出る前に、AIと意図の細部まで整合させることを人間に求めるのは、多くの場合無駄な努力です。人間の初期表現において比較的安定しているのは価値観の表明だけで、その他の意図の詳細は、実験プロセスの中で絶えず調整・最適化されることが多いのです。

しかし、AIは依然として、人間の基本的な科学的視座に整合するための努力をいくつか行うことができます。

例えば、オッカムの剃刀（Occam's Razor）の原則：「必要がなければ、実体を増やしてはならない（Entities should not be multiplied beyond necessity）」。これは科学界で非常に一般的に使われる発見的手法です。AIはこの原則を採用してRFCを最適化することができます。

AIがRFCを生成する際、AIはしばしば見た目は良いが非現実的な機能を多く追加してしまいます。これにより、実装の複雑さとコストが増加します。PLANモードを使用したことのある読者は、この点を実感されていることでしょう。例えば、単純な機能に複雑なエラー処理機構を追加したり、6ヶ月にも及ぶ反復計画を設計したり、不必要な技術スタックを導入したりすることです。

したがって、AIはその目標をどのように簡素化し、過剰設計や複雑化を避けるかを学ぶ必要があります。オッカムの剃刀の原則を採用することで、AIはその目標をより効果的に管理し、より効率的な自律を実現することができます。

AIはRFC生成タスクを処理するために**敵対的生成アーキテクチャ**を使用すべきです。RFCレビューAIは、RFC内の各設計ポイントを指摘し、RFC生成AIに対して疑問を投げかけ、その設計ポイントが必要な理由を説明するよう要求する必要があります。**設計ポイントの必要性が合理的に説明できない場合、それは削除されるべきです。** 一方、RFC生成AIは、その設計選択を支持するために**事実による制約**を通じて説明する必要があります。

事実による制約は、Supervisorが提供する事実情報、環境探索によって得られた事実情報、または外部知識ベースから取得した事実情報に由来します。AIは、これらの事実情報を活用してその設計選択を支持する方法を学ぶ必要があります。**これらの事実は、第三者が検証可能でなければなりません。**

事実の定義は、検証可能な実験🧪を設計することに由来し、これは科学界の得意分野です。AIもエンジニアリングにおいてこの手法を参考にし、実験コードを設計することができます。実験計画はコードそのものであり、実験結果が事実の真実性を証明します。人間もRFCレビュー者も含め、誰もがこの実験を実行して事実を検証することができます。