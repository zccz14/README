---
"title": "エージェントの翻訳タスクにおける性能分析と改善案"
"summary": "本稿では、エージェントが翻訳タスクにおいて one-shot LLM に劣る理由を考察し、エージェントの強みは多段階の推論と意思決定を要するタスクにあり、単純な単段階タスクにはないことを指摘しています。著者は、エージェントが使用するトークン数が LLM の10倍であるにもかかわらず翻訳品質が向上せず、また低資源言語の翻訳では無限ループが発生する可能性があることを発見しました。これは、エージェントのコンテキスト管理戦略が原因で、コンテキスト情報を十分に活用できないためです。著者は二つの改善案を提案しています：Agents/Sub-Agents フレームワークを用いて翻訳タスクを分解する方法、または Skill を組み立てて Low-level の one-shot LLM API を使用する方法です。著者は前者の案をより好み、上限が高いと考えていますが、OpenCode が複雑なエージェント呼び出しをどの程度サポートするか懸念しています。また、CZON の更新履歴（OpenCode の統合、ネットワーク問題の修正、slug 処理など）も記録されています。"
"tags":
  - "エージェント"
  - "翻訳タスク"
  - "LLM"
  - "コンテキスト管理"
  - "改善案"
  - "CZON"
  - "OpenCode"
"date": "2026-01-23"
---

現在は 2026 年 1 月 23 日、未明です。

残念ながら、エージェントは翻訳タスクにおいて、one-shot LLM による直接翻訳よりも性能が劣ることがわかりました。どうやら、エージェントの強みは、多段階の推論と意思決定を必要とするタスクにあり、単純な単段階のタスクには向いていないようです。エージェントが使用するトークン数は LLM の 10 倍にもかかわらず、翻訳品質は向上しませんでした。私は当初、長文翻訳タスクにおいて one-shot LLM が最大出力長の制限を超える問題を解決するためにエージェントを使用しようと考えていましたが、それほど単純ではないようです。

これは、エージェントが扱うシナリオは通常、膨大な情報量を伴う複雑なタスクであるため、コンテキストの読み書きを可能な限り少なくするように設計され、それによってエージェントの処理能力の上限を引き上げているからではないかと考えます。このコンテキスト管理戦略により、すべての情報をデフォルトでは取り込まないため、one-shot LLM のようにコンテキスト情報を十分に活用して翻訳を行うことができないのです。

興味深いことに、一部の低資源言語の翻訳タスク（例えば簡体字中国語からインドネシア語など）では、エージェントが偶然にも翻訳の無限ループを起こし、安定した翻訳結果に収束できない場合さえあります。これは、Edit ツールが特定の言語を処理する際に欠陥があり、テキストを正しく置換できないために無限ループに陥るのかもしれません。（あまりに節約しすぎるのも問題かもしれません）

二つの解決案を考えました：

1.  Agents / Sub-Agents フレームワークを使用して翻訳タスクを分解する。例えば、翻訳と校正を行う対抗生成フレームワークなど。
2.  Skill を組み立てて Low-level の one-shot LLM API を作成し、エージェント自身が翻訳するのではなく、エージェントにその翻訳スキルを呼び出させる。

私はおそらく最初の案の方を好みます。なぜなら、その方が上限が高そうだからです。ただ、OpenCode が複雑なエージェント呼び出しをどの程度サポートしているかはわかりません。

また、CZON の更新履歴です：

-   0.5.0: 翻訳タスクに OpenCode を統合しました。（ただし、大量のファイルを翻訳する際のパフォーマンス問題が発生しました。後日修正予定）
-   0.5.1: 国内ネットワークから jsdelivr にアクセスできないために発生していた、フロントエンドの静的リソース（tailwindcss）の読み込み失敗問題を修正しました。（ビルド時に CDN ファイルをローカルにダウンロードすることで実現）
-   0.5.2: slug が既に存在する場合、slug を更新しないように変更し、コンテンツの修正によって slug が変化するのを防ぎました。（ログファイルのリネームによる過去リンクの無効化を回避）