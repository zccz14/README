---
title: モジュールレベルにおける人間-AI協調のソフトウェアエンジニアリングアーキテクチャ
summary: 本稿では、LLMをモジュールレベルでの人間-AI協調ソフトウェアエンジニアリングに適用する際の限界、例えば非強制的な調整や有限の計算リソースなどについて考察し、インターフェース命名、単体テスト、ベンチマークテストを通じて人的介入を削減する方法を提案します。これにより、効率向上とコスト削減を目指します。
tags:
  - 人間-AI協調
  - ソフトウェアエンジニアリング
  - LLM
  - AI Agent
  - モジュール設計
  - 人的介入
  - 効率最適化
inferred_lang: ja
---

# モジュールレベルにおける人間-AI協調のソフトウェアエンジニアリングアーキテクチャ

## 問題の背景

LLMを用いてモジュールレベルでの人間-AI協調エンジニアリングアーキテクチャを設計し、産業レベルのアプリケーションモジュールの設計、実装、反復を高効率で完了させ、人的介入コストを削減することを目的としています。

1.  既存のAIエージェント（Claude Code、CodeX）は、コードモジュールの実装品質が低く、依然として人間による高度な介入、手直し、レビューが必要です。
2.  既存のAIエージェントは、実装プロセスにおいてモジュール境界を構築することが難しく、多くの無駄な複雑さを持つコードを生成してしまいます。
3.  既存のAIエージェントの実装は遅すぎ、タスクの開始から受け入れまでに10〜30分かかります。

## 問題の洞察

### なぜエージェントは一度ですべての作業を完了できないのか？

LLMの知能は永遠に制限されているからです。

これには主に2つの理由があります：（アーキテクチャ制約）非強制的な調整、（リソース制約）有限の計算リソース予算。副次的な理由として（認知制約）認知の非圧縮性があります。

**非強制的な調整**: LLMは何かを言わなければ、何かをしなければならないと強制されますが、結果が必ずしもすべての制約を遵守することを保証できません。もしLLMが必ず回答し、かつすべての制約を遵守することを強制すると仮定した場合、解くのが困難または不可能な問題を問いかけると、計算は麻痺してしまいます。LLMはその基盤設計において、強制的な調整ではなく、確率が最も高いトークンを強制的に出力することを選択しています。（停止問題）
いくつかの困難な問題は、複雑な関心事の間で良い解決策を見つける必要があります。LLMのコンテキストは、プロジェクト管理、設計、実装、受け入れを同時に含むことはできません。これらは完全に矛盾し、対立的なものです。関心の分離を実現したアーキテクチャのみが、エージェントが行き詰まることを防げます。LLMは出力する前に、実際にはすべての制約を遵守することを強制されていません。なぜなら、それは思考の崩壊を引き起こすからです。

**有限の計算リソース予算**: 明らかに、より賢いLLMはより多くの関心事を同時に考慮する能力を持ちますが、その代償は必ずより高い計算リソースです。いわゆるAGIは、常にコストを度外視した条件下での天井目標であり、商用汎用LLMの目標ではありません。そして、そのような高い計算リソースを使って問題を解決するかどうかは、ビジネスが決定することです。したがって、汎用LLMはこのことを自ら決定することはできません。この根本的な矛盾は解決できません。（経済的制約）
ミュンヒハウゼンの三難問題に注意してください。思考そのものの無限性と思考予算の有限性は永遠に衝突します。私たちは理想として、AIを神のような存在にしたいと考えていますが、実際にはそれは永遠に有限の知能でしかありえません。なぜなら、その思考はリソースを消費するからです。

比較的副次的な理由：

**認知の非圧縮性**: ビジネスロジックを解決するには、十分な情報入力が必要です。もし一言でLLMに説明できると考えるなら、それはその認知の伝達が圧縮可能であることを意味します。実際には、LLMが置かれている環境の複雑さを知るために、多くの文脈を補足する必要があります。
なぜこれが副次的な理由と言えるかというと、この理由にはいくつかの課題があるからです：すなわち、常識自体はすでにLLMの事前学習に組み込まれており、多くの認知はLLMがますます強力になるにつれて、徐々に小さな問題になっていきます。次に、LLMはまず推測して補完し、人間と迅速に調整を行うことができ、これも矛盾を緩和します。しかし、現状に基づけば、まだ大きな問題があります。
多くの経験豊富なLLMユーザーは、これがもたらす問題を認識していることでしょう。

しかし、朗報があります。エージェントが創発する閾値は、エージェントが少なくとも一つの関心事に対して有効な出力を生成できることであり、これは明らかにすでに達成されています。私たちは、限られた知能をツールとして長期的に活用し、私たちのビジネスを完了させる必要があります。

### 人的介入をどのように減らすか？

鍵は、人間の懸念を払拭することです。そうすれば、人間は「使えないわけではない」という気持ちから、AIの作業成果に対してそれ以上厳しく求めなくなるでしょう。

では、どのようなチェックを通過した後、人間は自分には介入する能力がない、あるいはそれ以上の措置を取る必要がないと判断するのでしょうか？

1.  モジュールが外部に公開するインターフェースの概念命名が、要求に合致していること。不合理なインターフェースがシステム下流に蔓延するという懸念を払拭します。
2.  単体テストを通過すること。このモジュールが正常に動作するかどうかという懸念を払拭します。
3.  ベンチマークテストにおいて最適化されているか、少なくとも劣化していないこと。このモジュールの効率が非常に低いのではないかという懸念を払拭します。
    最初の点は初期段階で発見できますが、後の点は実験が終了して初めて知ることができます。もしこの3つすべてが満たされていれば、人間がAIが完了した作業に強引に介入する理由はありません。

このモジュールが実際のデータパターンに対応できるかどうかについては、本番環境のデータを使用してテストする必要があります。その後、人間がそのパターンを要約し、意図に基づいて新しいモジュールを構築し、新しい問題を解決します。この問題は、本稿の議論範囲外とします。

### 優先目標

1.  人的介入を削減する。
2.  実行時間を短縮し、速度を向上させる。
3.  Token使用量を削減し、LLM費用を削減する。