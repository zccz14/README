---
"title": "Multi-Agents Adversarial Generation Translation and Optimization Strategies"
"summary": "This article explores the application of Multi-Agents in translation tasks, significantly improving translation quality through adversarial generation models (translation model vs. review model), addressing issues of content omission, incoherence, and unnaturalness, albeit at the cost of time and token efficiency. Simultaneously, the article discusses memory optimization strategies, such as integrating agents into a single process to save memory; in control constraints, combining the advantages of soft and hard constraints, proposing the use of Orchestrator Agent to generate scripts for flexible and reliable control; and compares the ecosystem openness of OpenCode vs. Claude, emphasizing OpenCode's API-friendly nature for easier integration."
"tags":
  - "Multi-Agents"
  - "Adversarial Generation Translation"
  - "Memory Optimization"
  - "Control Constraints"
  - "OpenCode"
  - "Claude"
  - "Translation Quality"
  - "Agent Collaboration"
"date": "2026-01-25"
---

It is now January 25, 2026, Sunday afternoon.

**Multi-Agents: Adversarial Generation Translation**

Yesterday, I completed the lightweight OpenCode translation integration for CZON, implementing a basic adversarial generation model.

This translation task introduces both translation and review tasks. The two engage in adversarial generation: the translation model is responsible for generating translation results, while the review model is responsible for reviewing whether the translation results are qualified. If the review model deems the translation results unqualified, it requires the translation model to regenerate until qualified translation results are produced. (Currently, the maximum iteration count is 10 to prevent infinite loops.)

Compared to the original one-shot LLM translation, this translation design sacrifices time and token efficiency. However, it has a key advantage: significantly improving translation quality, addressing the following issues:

1. **Content omission in translation**: Some translation models may miss certain content from the original text, resulting in incomplete translations. The review model can check whether the translation includes all original content, ensuring completeness.
2. **Incoherence in long article translation**: Some translation models may produce inconsistent results when processing long articles. The review model can check the coherence of translations, ensuring overall consistency.
3. **Unnatural and awkward phrasing**: Some translation models may generate translations that appear stiff or unnatural. The review model can evaluate the fluency of translations, ensuring they conform to the expression habits of the target language.

From the results, translation quality clearly takes priority over token efficiency and time efficiency. For scenarios like CZON that require high-quality translation, the adversarial generation model is a good choice.

**Multi-Agents Memory Optimization**

We cannot launch a separate process for each Agent, as each process consumes at least 100MB of memory. Running multiple Agents simultaneously would lead to insufficient memory. A better approach is to integrate all Agents into a single process to save memory overhead. OpenCode officially separates Server and Client - it can use a serve process to listen on a port (default 4096), then multiple Clients connect to this port for interaction. This allows all Agents to run within a single Server process, with Clients only responsible for sending requests and receiving responses.

This way, we should be able to support launching hundreds of translation tasks simultaneously without crashing due to insufficient memory.

**Multi-Agents Control Constraints**

The industry has two approaches: having Agents control other Agents, or using Scripts to control Agents.

The difference is that Agent-controlled-Agent is a soft constraint, where Agents can decide whether to execute another Agent's instructions based on their own judgment; while Script-controlled-Agent is a hard constraint, where Agents must strictly follow the Script's instructions.

Soft constraints offer flexibility but lack reliability; hard constraints offer reliability but lack flexibility.

The problem with soft constraints is common: workflows are defined in Agents, but Agents often don't follow these workflows, sometimes even exiting prematurely, leading to unexpected results. The problem with hard constraints is that Scripts may not cover all scenarios, preventing Agents from handling certain special situations.

While these two approaches seem incompatible, we can actually use an Orchestrator Agent to generate Scripts, then have other Agents execute tasks according to these Scripts. This combines the advantages of both approaches, offering both flexibility and reliability. In early stages, we can even manually write Scripts to control Agent behavior. Complete control is the ultimate flexibility.

Therefore, we need to make Script-calling-Agent friction sufficiently small - small enough to be implemented with a single line of code, thereby enabling complex multi-Agent collaboration.

Anthropic's [article](https://www.anthropic.com/engineering/multi-agent-research-system) on Multi-Agent systems mentions that sub-Agent outputs are best written to the file system rather than returned to the main coordinator. Therefore, we can consider that Script-calling-Agent doesn't need to return results; we only need Agents to write results to the file system, then have other modules read the results from the file system.

As for Scripts, they can be integrated into commonly used languages, such as JavaScript, using a library to enable Orchestrator Agents to first encode Scripts, then have Scripts call other Agents to execute tasks. No DSL needed - better than DSL.

**Multi-Agents Ecosystem: OpenCode vs Claude Code**

OpenCode's ecosystem is clearly more open than Claude's. OpenCode allows calling Agents via HTTP API (or SDK), viewing Agent Session status, obtaining Agent output results, etc. This makes it easier for us to integrate OpenCode Agents into our systems, enabling complex multi-Agent collaboration. Claude, on the other hand, takes the opposite approach, trying to close its ecosystem, only allowing Claude Agents to be called through interfaces provided by Anthropic, limiting user freedom.