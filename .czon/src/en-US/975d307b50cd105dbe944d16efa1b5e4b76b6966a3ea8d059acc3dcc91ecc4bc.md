---
title: AI Programming Failures and Rewriting Experiences
summary: The author rewrote the ZEN project due to poor quality of AI-generated object-oriented code and exploding technical debt, shifting towards procedural and functional programming, and suggests avoiding excessive backward compatibility to improve code quality.
tags:
  - AI Programming
  - Object-Oriented Programming
  - Functional Programming
  - Technical Debt
  - Code Quality
  - Occam's Razor
  - Backward Compatibility
inferred_date: 2025-01-07
inferred_lang: en-US
---

Today is 2025-01-07.

Vibe Coding was a massive failure. The code quality generated by AI was too poor to be usable. I was forced to completely rewrite the ZEN project, implementing it using traditional, old-school programming methods.

I used AI to generate code from scratch. After multiple iterations, the project's quality began to collapse. New features couldn't be integrated, bugs emerged endlessly, the code structure became chaotic, and even deleting functionality became exceptionally difficult. These are classic symptoms of exploding technical debt. Consequently, I decisively intervened and decided to rewrite the entire project. A key insight was that the quality of the OOP code written by AI was particularly poor. For every new feature, it would create a separate class and then punch holes in other related classes to call it, resulting in a large number of useless classes and methods. This wasn't object-oriented programming; it was requirement-list-oriented programming.

The reasons, I believe, are:

1.  AI's design capability for the object-oriented programming paradigm is insufficient, likely due to a lack of modeling for business domain concepts.
2.  AI doesn't know whether it's writing throwaway code or code for long-term maintenance. Lacking architectural guidance, it adopts a lazy, "just get it done" strategy.
3.  There's a lack of an AI-friendly scaffolding, making the bootstrapping process from scratch quite difficult for AI.
4.  AI is overly conservative in handling compatibility requirements, leading to bloated code.

## The Myth of Object-Oriented Programming

I believe AI is currently not well-suited for writing object-oriented code. Object-oriented programming requires a deep understanding and modeling capability of the business domain, which AI currently cannot handle. Ironically, even humans often struggle with this. In contrast, procedural and functional programming are more suitable for AI because they focus more on data transformation and processing rather than object state and behavior.

If you use object-oriented programming, you need the AI to be proficient in design patterns and refactoring simultaneously to produce high-quality OOP code. However, if you use procedural and functional programming, the AI only needs to focus on algorithms and data structures to write decent code.

So, what are the benefits of object-oriented programming? Encapsulation? Inheritance? Polymorphism? In the age of AI, these seem less critical because they were born from the need to write less code and facilitate team collaborationâ€”concerns that AI doesn't share. Instead, code readability, maintainability, and testability are key. These qualities are more easily achieved through functional and procedural programming.

## Excessive Backward Compatibility

AI is overly conservative about backward compatibility, leading to severely bloated code. AI always tries to preserve all old features and interfaces to prevent breaking existing code. However, this approach often backfires by increasing code complexity and maintenance costs. Sometimes, deleting old features and interfaces can simplify the code and improve performance. But AI struggles to make such trade-offs because it lacks an understanding of business requirements and user behavior.

If AI treats all public exports as sacred and must be preserved, it introduces these interfaces casually when creating new features. Yet, during subsequent maintenance, it treats these junk interfaces like treasures, afraid to delete them by accident. The result is increasingly bloated code, rising complexity, and more bugs.

After I tried guiding the AI to adopt a "allow breaking changes" strategy, the situation improved significantly. This indicates we identified the core problem. However, it also raises a new question: how do we manage the risks associated with breaking changes?

We must make AI understand the principle of **Occam's Razor**: "Entities should not be multiplied without necessity."
In other words, code should be as simple as possible, avoiding unnecessary complexity and redundancy. New features and interfaces should only be introduced when genuinely needed. This is the only way to maintain code clarity and maintainability.

If AI doesn't separate design and coding tasks, achieving this becomes very difficult.

## Conclusion

1.  **Emphasize avoiding OOP and shift towards procedural and functional programming.** This is a crucial shortcut that can significantly improve the quality and maintainability of AI-generated code.
2.  **Guide AI to understand the Occam's Razor principle**, avoid excessive backward compatibility, and reduce code bloat.

I haven't fully figured out solutions for other issues yet, such as the scaffolding problem and architectural guidance.