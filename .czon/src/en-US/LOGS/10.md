---
"title": "Thoughts on AI Agent Module-Level Software Engineering Architecture Design"
"summary": "This article documents the author's thoughts on the application of AI Agents in module-level software engineering on January 12, 2026. The author proposes a human-machine collaborative architecture. Key points include using git worktree to manage code repositories, invoking AI Agents (such as Claude Code) via CLI and managing sessions, obtaining Agent completion notifications and conversation history to achieve transparency. The author plans to implement an automated script that assigns each task to an independent Agent session and coordinates the workflow via a scheduler. The article emphasizes the advantage of using an Agent over directly calling an LLM API: the Agent handles underlying complexities (such as exploring codebases, invoking system commands, context management), avoiding the need to reinvent the wheel. The author intends to first implement a simplified version to validate the concept."
"tags":
  - "AI Agent"
  - "Software Engineering"
  - "Human-Machine Collaboration"
  - "Claude Code"
  - "Automation"
  - "Modularity"
  - "Transparency"
  - "Scheduler"
"date": "2026-01-12"
---

Today is Monday, January 12, 2026, morning.

I woke up early today and reflected on the AI Agent design discussion with C1 yesterday. I found it quite enlightening and felt the need to document it.

Referencing the [previous context](../INSIGHTS/1.md), I designed a module-level human-machine collaborative software engineering architecture.

I am considering how to implement it.

In simple terms, the key points are:

1.  Need to manage code repositories using the `git worktree` command and provide a setup script for each Repo.
2.  Need to invoke an AI Agent (Claude Code, OpenCode, ...etc) via CLI, pass a prompt, and start a session.
3.  Need to be able to receive a completion notification from the AI Agent.
4.  Need to be able to access the intermediate conversation history of the AI Agent; otherwise, transparency cannot be achieved. Referencing the controllable trust issue mentioned in [this document](../INSIGHTS/2.md), we need in-process transparency and controllability.

Based on these capabilities, I can implement an automated script to handle module-level software engineering tasks.

Taking Claude Code as an example:

1.  Claude Code can be invoked via CLI by directly passing a prompt to start a new session.
2.  When Claude Code outputs results to stdout using the `-p` parameter, it signals completion.
3.  Claude Code provides the ability to pass a session ID, allowing one to locate the corresponding conversation history file in the `.claude` directory and thus obtain the message history.

Given this, I can write a script to manage this work.

Each Session is independent and clean. Each Session will be assigned to an Agent to complete.

An Agent instance can be abstracted as an interface, regardless of whether its underlying implementation is Claude Code or something else.

The scheduler will then coordinate different Agents to complete tasks according to our predefined workflow.

Why base it on an Agent rather than an LLM API? Because the Agent handles the underlying logic for us: exploring the codebase, invoking operating system commands, context management, and adapting to the LLM API. This is a complex system, and I believe we don't need to reinvent the wheel unless it doesn't meet the requirements.

I plan to first implement a minimal version to validate whether this approach is feasible. Please look forward to subsequent progress records.