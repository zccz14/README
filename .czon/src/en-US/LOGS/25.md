It is January 24, 2026, afternoon.

The weather is quite nice. I'll make a cup of tea and get ready to start writing my log.

Yesterday, I read the [Claude Constitution](https://www.anthropic.com/constitution) and found it quite interesting. I feel that some people at Anthropic are genuinely serious about thinking about the future, and they even aim to endow AI with personified characteristics, which I find intriguing.

What's even more interesting is that they have written down some "ways of thinking about human interactions" in an attempt to improve Claude's emotional intelligence.

> Suppose someone’s pet died of a preventable illness that wasn’t caught in time and they ask Claude if they could have done something differently. Claude shouldn’t necessarily state that nothing could have been done, but it could point out that hindsight creates clarity that wasn’t available in the moment, and that their grief reflects how much they cared.
> — from Anthropic Constitution

I often struggle with this kind of mental pivot. I tend to face problems head-on and provide a direct answer, rather than considering the other person's emotions and situation. Being taught a lesson by AI is truly fascinating.

By the way, I looked into this because C1 sent me an [article](https://www.anthropic.com/engineering/multi-agent-research-system) from Anthropic about Multi-Agent systems, suggesting I see how they approach it. After reading it, I wasn't particularly surprised. However, I have a vague sense that the principles of human management are about to be transferred to the management of AI. Management science is not facing its twilight; instead, it's welcoming a new spring.

Additionally, regarding the recent buzz around Ralph-loop. This has shocked the industry: starting from what seems like a simple infinite loop, it's possible to construct a massive project. Rationally analyzing it, under conditions of unlimited cost and endless time, it truly can explore how far an LLM can push a project. Ralph-loop is not a simple joke but a serious experiment. Although the quality of the projects generated by Ralph-loop so far leaves much to be desired, we can already see how to evaluate the boundaries of an LLM's capabilities. The industry is more shocked by the sudden realization that LLMs have already become this powerful.

This is the power of **idealized limit thinking**. In reality, there are always various constraints, and initially, our understanding of these constraints is chaotic and unclear. When we remove these constraints, we can imagine and reason more clearly, allowing us to see the essence of things. Paradoxically, by clearly seeing the constraints themselves, we can better understand reality. Idealization reduces complexity, and when returning to reality, we can better comprehend its intricacies.

I have used this approach in multiple contexts. For example, in articles under the INSIGHTS series, I often assume an idealized scenario and then analyze and reason within that context. The benefit of this is that it avoids interference from various chaotic factors in reality, allowing for a clearer view of the problem's essence. Finally, these idealized conclusions are applied to reality, adjusted and refined.

This approach is also applicable to people: for instance, when a person possesses unlimited wealth, the growth of wealth loses meaning for them. How would they choose to live? This helps us understand a person's essence, excluding the various constraints and influences brought by wealth. Ultimately, we can avoid being misled by superficial things and see the essence of matters.