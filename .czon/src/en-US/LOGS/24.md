It is January 23, 2026, in the afternoon.

I had some bad street food last night, and today I'm physically and mentally exhausted. Still struggling with the integration of OpenCode.

A major blow is that today OpenCode removed the free models GLM-4.7 and MiniMax M2.1. What's left are only models like big-pickle, gpt-5-nano, and grok-code. GLM-4.7 and MiniMax M2.1 were basically usable, while gpt-5-nano and grok-code perform poorly on summary tasks. The advantage of freeloading on OpenCode vanished instantly. Rumor has it that big-pickle is GLM-4.6, but OpenCode's official statement says big-pickle is a secret. It seems BYOK for CZONE users is inevitable; anyway, there's no way I'm paying out of my own pocket (laughs).

CZON has integrated a summary feature that can summarize all files. However, summary tasks place relatively high demands on the model, requiring it to understand the full text, think, and construct a summary. Fortunately, summary tasks aren't frequent, so it's acceptable to use more expensive models for them. Eagerly awaiting the arrival of DeepSeek V4, hoping for a better and cheaper model.