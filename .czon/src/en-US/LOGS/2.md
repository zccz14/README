---
"title": "Reflections on AI Programming Practices: Avoiding OOP and Over-Compatibility"
"summary": "This article documents the author's failed experience with AI-assisted programming (Vibe Coding), finding that the AI-generated object-oriented code was of poor quality and structurally chaotic, leading to an explosion of technical debt. The author analyzes the reasons, including the AI's insufficient design capability for OOP paradigms, lack of architectural guidance, and excessive backward compatibility. The article proposes key recommendations: avoid using object-oriented programming and shift towards procedural and functional programming; guide the AI to understand Occam's Razor to reduce code bloat. These measures aim to improve the quality and maintainability of AI-generated code."
"tags":
  - "AI Programming"
  - "Object-Oriented Programming"
  - "Functional Programming"
  - "Code Quality"
  - "Technical Debt"
  - "Occam's Razor"
  - "Backward Compatibility"
"date": "2026-01-07"
---

Today is 2026-01-07.

A major failure with Vibe Coding—the code written by the AI was of such poor quality that it was completely unusable. I was forced to completely rewrite the ZEN project, switching back to traditional, old-school programming methods.

I used the AI to generate code from scratch. After several iterations, the project's quality began to collapse: new features couldn't be integrated, bugs emerged endlessly, the code structure became chaotic, and even deleting functionality became exceptionally difficult. These are classic symptoms of technical debt explosion. Consequently, I decisively intervened and decided to rewrite the entire project. A key observation was that the OOP code written by the AI was particularly poor in quality. For every new feature, it would create a separate class and then "poke a hole" in other related classes to call it, resulting in a large number of useless classes and methods. This isn't object-oriented programming; it's more like requirement-checklist-oriented programming.

The reasons, I believe, are:

1.  The AI has insufficient design capability for object-oriented programming paradigms, likely due to a lack of modeling for business domain concepts.
2.  The AI doesn't know whether it's writing throwaway code or code for long-term maintenance. It lacks architectural guidance and resorts to a lazy, "hack it together" strategy.
3.  There's a lack of an AI-friendly scaffolding or boilerplate, making the bootstrapping process from scratch quite difficult for the AI.
4.  The AI is overly conservative in its handling of compatibility requirements, leading to code bloat.

## The OOP Myth

I believe AI is currently not well-suited for writing object-oriented code. OOP requires a deep understanding and modeling capability of the business domain, which AI currently cannot handle. Ironically, even humans often struggle with this. In contrast, procedural and functional programming are more suitable for AI, as they focus more on data transformation and processing rather than object state and behavior.

If you use OOP, you need the AI to be proficient in design patterns and refactoring to produce high-quality object-oriented code. However, with procedural and functional programming, the AI only needs to focus on algorithms and data structures to write decent code.

So, what are the benefits of OOP? Encapsulation? Inheritance? Polymorphism? In the age of AI, these seem less critical, as they were born from the need to write less code and facilitate team collaboration—concerns that are irrelevant to AI. Instead, code readability, maintainability, and testability are key. These qualities are more easily achieved through functional and procedural programming.

## Excessive Backward Compatibility

The AI is overly conservative about backward compatibility, resulting in severely bloated code. It always tries to preserve all old features and interfaces to prevent breaking existing code. However, this approach often backfires by increasing code complexity and maintenance costs. Sometimes, deleting old features and interfaces can simplify the code and improve performance. But the AI struggles to make such trade-offs because it lacks an understanding of business requirements and user behavior.

If the AI treats every public export as something that must be preserved, it introduces these interfaces casually when creating new features but later treats these junk interfaces like treasures, afraid to delete them by accident. The result is increasingly bloated code, rising complexity, and more bugs.

After I tried guiding the AI with a "allow breaking changes" strategy, the situation improved significantly. This indicates we've identified the core problem. However, it also raises a new question: how do we manage the risk of breaking changes?

The AI must understand **Occam's Razor**: "Entities should not be multiplied without necessity."
In other words, code should be as simple as possible, avoiding unnecessary complexity and redundancy. New features and interfaces should only be introduced when genuinely needed. This is the only way to maintain code clarity and maintainability.

If the AI doesn't separate design and coding tasks, achieving this is very difficult.

## Conclusion

1.  **Emphasize avoiding OOP and shift towards procedural and functional programming.** This is a crucial shortcut that can significantly improve the quality and maintainability of AI-generated code.
2.  **Guide the AI to understand Occam's Razor**, avoid excessive backward compatibility, and reduce code bloat.

Other issues, such as the scaffolding problem and architectural guidance, remain unresolved for now.