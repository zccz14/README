---
"title": "Analysis of Agent Performance in Translation Tasks and Improvement Proposals"
"summary": "This article analyzes why Agents underperform compared to one-shot LLMs in translation tasks, including high token usage, decreased translation quality, and YAML Frontmatter formatting errors. The author believes that Agent design is better suited for multi-step reasoning and decision-making tasks, and its context management strategy prevents it from fully utilizing information for translation. The article also mentions that Agents may enter infinite loops when translating low-resource languages. To address these issues, the author proposes two improvement approaches: using an Agents/Sub-Agents framework to decompose translation tasks, or using Skills to assemble a low-level one-shot LLM API for translation. The author prefers the first approach and discusses OpenCode's support for complex Agent calls. Finally, the article reviews the changelog for CZON versions 0.5.0 to 0.5.2, including OpenCode integration, network issue fixes, and the rollback of the Agent translation feature."
"tags":
  - "Agent"
  - "Translation Task"
  - "LLM"
  - "OpenCode"
  - "CZON"
  - "Performance Analysis"
  - "Improvement Proposal"
"date": "2026-01-23"
---

It is now January 23, 2026, early morning.

Unfortunately, I've found that Agents perform worse than one-shot LLMs in direct translation tasks. It seems the strength of Agents lies more in tasks requiring multi-step reasoning and decision-making, rather than simple single-step operations. Agents use about 10 times more tokens than LLMs, yet the translation quality actually degrades, especially with issues like YAML Frontmatter being translated incorrectly, leading to formatting errors.

My initial intention was to use them to solve the problem of one-shot LLMs exceeding maximum output length limits in long-text translation tasks, but it appears it's not that straightforward. Consequently, I rolled back this feature in CZON@0.5.2 to reconsider the approach.

I believe this might be because Agent scenarios typically involve complex tasks with massive amounts of information. Therefore, they are designed to minimize reading and writing to context, prioritizing local file operations to increase their data processing capacity. This context management strategy means they don't default to incorporating all available information, preventing them from leveraging context as effectively as one-shot LLMs do for translation.

Interestingly, for some low-resource language translation tasks (e.g., Simplified Chinese to Indonesian), Agents occasionally exhibit behavior akin to an infinite translation loop, failing to converge to a stable translated result. This might be due to flaws in how the Edit tool handles certain languages, causing it to incorrectly replace text and thus get stuck in a loop. (Being too economical might also have its downsides.)

I've thought of two potential solutions:

1.  Use an Agents / Sub-Agents framework to decompose the translation task, for example, an adversarial generation framework involving translation and proofreading.
2.  Use Skills to assemble a low-level one-shot LLM API, allowing the Agent to call a translation skill instead of performing the translation itself.

I'm leaning towards the first solution, as its potential ceiling seems higher. I'm just not sure about OpenCode's level of support for complex Agent calls.

Additionally, the CZON changelog:

-   0.5.0: Integrated OpenCode for translation tasks. (However, this introduced performance issues with large-scale file translation, later fixed.)
-   0.5.1: Fixed frontend static resource loading failures (tailwindcss) caused by inability to access jsdelivr from within China. (Achieved by downloading CDN files locally during the build phase.)
-   0.5.2: When a slug already exists, it is no longer updated to prevent slug changes due to content modifications. (This avoids historical link breakage caused by log file renaming); Rolled back the Agent translation feature, removing OpenCode integration for translation tasks.