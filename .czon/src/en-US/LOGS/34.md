---
"title": "Application of AI Autonomy and Scientific View Alignment in RFC Design"
"summary": "This article discusses the importance of AI autonomy in software engineering, particularly in the context of RFC (Request for Comments) design. The author points out that the core of AI autonomy lies in the alignment of scientific views, meaning AI needs to understand and adhere to human scientific concepts and methodologies, such as Occam's Razor, to avoid over-engineering and unnecessary complexity. The article suggests adopting an adversarial generation architecture, where an RFC review AI questions the design choices made by the generation AI, and supports design decisions through factual constraints. These facts must be third-party verifiable, which can be achieved by designing experimental code for validation. The ultimate goal is to achieve efficient AI autonomy, reduce the cost of human intervention, and promote agile development models."
"tags":
  - "AI Autonomy"
  - "Scientific View Alignment"
  - "RFC Design"
  - "Occam's Razor"
  - "Adversarial Generation Architecture"
  - "Factual Constraints"
  - "Human-Machine Collaboration"
  - "Agile Development"
"date": "2026-01-29"
---

It is now Thursday, January 29, 2026, at noon.

I've adjusted my schedule to wake up in the mornings.

Yesterday, I discussed LegionMind's RFC [^1] feature with C1. He mentioned:

> After modularization, the overall workflow has become slower, making early-stage document alignment even more critical.
>
> It's somewhat like moving towards a waterfall development model as the cost and effort of implementation increase.
>
> Is there an agile model suitable for AI's working speed? That would definitely be agile development driven by AI autonomy.
>
> Providing AI with facts and enabling it to correctly understand **facts** and **intentions** becomes more important, allowing for effective intermediate reviews and agile iterations.

[^1]: Yes. It's the IETF's RFC (Request for Comments) standard. In the [Module-Level Human-Machine Collaborative Software Engineering Architecture](../INSIGHTS/1.md), the Protocol Spec is named RFC because its functionality is very similar to RFCs. We hope AI can describe its features and interfaces in the style of an RFC.

My comment on this is:

AI autonomy is correct because the cost of human intervention is too high. But how can AI achieve autonomy? The core lies in the alignment of scientific views.

## The Core of AI Autonomy is the Alignment of Scientific Views

**The core of AI autonomy lies in the alignment of scientific views.** In other words, AI needs to understand and adhere to human scientific concepts and methodologies.

Human intentions are sometimes vague, variable, and cannot be measured beforehand. Expecting humans to align every detail of their intentions with AI before experimental results are available is often futile. In initial human expressions, only value statements are relatively stable; other details of intention often need to be adjusted and optimized during the experimental process.

However, AI can still make efforts to align with basic human scientific views.

For example, Occam's Razor: "Entities should not be multiplied beyond necessity." This is a very common heuristic in the scientific community. AI can adopt this principle to optimize RFCs.

When AI generates RFCs, it often adds many seemingly ideal but impractical features. This increases implementation complexity and cost. Readers who have used the PLAN mode are likely familiar with this. For instance, adding complex error-handling mechanisms to simple functions, designing iteration plans spanning six months, or introducing unnecessary technology stacks.

Therefore, AI needs to learn how to simplify its goals and avoid over-engineering and unnecessary complexity. By adopting Occam's Razor, AI can manage its goals more effectively, thereby achieving more efficient autonomy.

AI should use an **adversarial generation architecture** to handle RFC generation tasks. The RFC review AI needs to point out every design decision in the RFC and question the RFC generation AI, asking it to explain why each design point is necessary. **If the necessity of a design point cannot be reasonably justified, it should be removed.** The RFC generation AI, in turn, must support its design choices through **factual constraints**.

Factual constraints come from facts provided by the Supervisor, facts obtained through environmental exploration, or facts retrieved from external knowledge bases. AI needs to learn how to use these facts to support its design choices. **These facts must be third-party verifiable.**

The definition of facts comes from designing a verifiable experiment ðŸ§ª, which has always been the forte of the scientific community. AI can also refer to this practice in engineering by designing experimental code. The experimental plan is the code itself, and the results of the experiment can prove the truth of the facts. Anyone, including humans and RFC reviewers, can run this experiment to verify the facts.