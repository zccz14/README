It is now the evening of January 21, 2026.

Yesterday, I spent a great deal of effort revising the article [Capital Protracted War](../INSIGHTS/6.md). After discussing it with friends and engaging in a rather in-depth back-and-forth with AI, I received some feedback. I worked until I was exhausted and didn't continue writing the log. I left it for today.

**Terminology and Academic Rigor**

I have given up on the idea of citing extensively to pretend this paper is highly persuasive. After all, for this kind of article, only successful practice makes it convincing. There is a certain philosophical component, but I haven't formally studied philosophy books, so I can't pretend to be knowledgeable. Rather than pretending, it's better to honestly admit I haven't read them and avoid using philosophical terms to deceive others and myself. As for economic terminology, I don't even want to mention it. It's inherently a highly interpretive discipline. Different schools of thought argue endlessly; being able to justify one's own view is enough.

This was never intended to be an article for academic publication, but rather one providing strategic practical guidance. It should use plain language so that everyone can understand it. Being overly academic can make it seem lofty and difficult to approach. Who has the spare time to read several monographs just to understand an article?

**Fundamental Purpose**

The fundamental purpose of the Capital Protracted War is to allow individual investors to leave the market after achieving victory, rather than being trapped in the market for a lifetime. The idea of achieving stable profits is essentially a false proposition. Making enough money in one go is the correct way to "reach shore." View the market as a boat for crossing a river; the goal is to reach the opposite bank, not to drift on the boat forever. Given this, clearly defining the standard for victory is the primary issue. Without a clear victory standard, how can we talk about strategy?

**What's the Difference from a Lottery?**

A lottery is ostensibly a fair, random game of probability. The market, however, is a game of strategy disguised as a game of probability. Investors can improve their odds of "winning" by refining their strategies, while lottery players rely solely on luck.

**If Everyone Adopts This Strategy, Will It Still Be Profitable?**

Yes. Because this strategy does not specify the underlying tactics. Everyone can have different underlying tactics but use this strategy to manage risk and capital. Even if everyone adopts this strategy, their floating profits will differ at various stages, their directional judgments, the instruments they participate in, etc., can all differ. Therefore, the variation will be significant, and it still won't lead to crowding.

**Regarding the "Collective Action Problem"**

During one exchange, the AI brought up the "collective action problem," where individual and collective interests diverge, and an individual's action can harm the collective, making that action difficult to implement. However, I argued that individuals in the market cannot take an action that is guaranteed to increase their own returns; adding to a position with floating profits also carries the risk of losing everything. However, the collective action problem applies to underlying tactics that involve coordinated action. But the Capital Protracted War does not assume everyone adopts the same underlying tactics.

**Regarding Theory Validation**

It can be validated through backtesting, measuring a strategy's T_S performance. Especially by backtesting on very long historical data, focusing on changes in the frequency of achieving victory. Furthermore, I have defined a quantitative expression for strategy failure: when T_S exceeds a threshold unacceptable to a human investor, such as 3 years. We can also study the T_S distribution of a strategy from very long-term data to obtain more supporting evidence.

So, I asked OpenCode + MiniMax M2.1 to help me implement a backtesting framework to verify this. Enough said; it produced something completely off-topic.

Today, to integrate OpenCode as part of a build process, I battled with OpenCode for three hundred rounds and was defeated. A precious record of early human attempts to tame AI. I think I can't keep avoiding building an Agents framework. I've already written several articles on my own Agents theory[^1] [^2] [^3], and this is, after all, the trend of the future. So I decided to tackle this problem head-on.

I decided to first build a minimal adversarial generation Agents framework to prevent AI from cutting corners. I consider this a very fundamental module, the foundation of all agent systems. This module's function is to have two agents generate outputs adversarially, thereby improving output quality. This module should be general-purpose and applicable to various agent systems.

Today, I was wrestling with OpenCode; C1 was wrestling with GitHub Project integration; Mage was wrestling with market manipulators on PolyMarket; and RYAN was wrestling with the notification module...

In short, everyone worked hard today.

[^1]: See [Software Engineering Architecture for Module-Level Human-Machine Collaboration](../INSIGHTS/1.md)

[^2]: See [How to Solve Human Desire for Control—On the Issue of Controllable Trust in Human-Machine Collaboration](../INSIGHTS/2.md)

[^3]: See [Embracing "Finite," Designing "Infinite"—A New Paradigm for Constructing Agent Systems Based on LLM Constraints](../INSIGHTS/3.md)