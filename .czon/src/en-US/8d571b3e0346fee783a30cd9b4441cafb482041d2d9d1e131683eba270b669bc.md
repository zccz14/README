---
"title": "Reflections on AI Agent Module-Level Software Engineering Architecture Design"
"summary": "This article documents the author's thoughts on January 12, 2026, regarding the application of AI Agents in module-level software engineering. The author proposes a human-machine collaborative architecture. Key points include using git worktree to manage code repositories, invoking AI Agents (such as Claude Code) via CLI and managing sessions, and obtaining the Agent's completion notifications and conversation history to achieve transparency. The author plans to implement an automated script that assigns each task to an independent Agent session and coordinates the workflow through a scheduler. The article emphasizes the advantage of using an Agent over directly calling an LLM API: the Agent handles underlying complexities (such as exploring codebases, invoking system commands, context management), avoiding the need to reinvent the wheel. The author intends to first implement a simplified version to validate the concept."
"tags":
  - "AI Agent"
  - "Software Engineering"
  - "Human-Machine Collaboration"
  - "Claude Code"
  - "Automation"
  - "Modularity"
  - "Transparency"
  - "Scheduler"
"date": "2026-01-12"
---

Today is Monday, January 12, 2026, morning.

I woke up early today and reflected on the AI Agent design issues discussed with C1 yesterday. I found some insights worth recording.

Referencing the [previous context](czon://f14dd5dd9a733022055d249db9b1ed3d60d9b60b7eb8c063fe24c02774b6b631), I designed a module-level human-machine collaborative software engineering architecture.

I am considering how to implement it.

In simple terms, the key points are:

1.  Need to manage the code repository using the `git worktree` command and provide a setup script for each Repo.
2.  Need to invoke the AI Agent (Claude Code, OpenCode, ...etc) via CLI, pass in a prompt, and start a session.
3.  Need to be able to receive the AI Agent's completion notification.
4.  Need to be able to access the AI Agent's intermediate conversation history; otherwise, transparency cannot be achieved. Referencing the controllable trust issue mentioned in [this document](czon://3a40b7b252512466f0b0feb8c7ea77fc624bb0026cbae8882c5c205462e0aa64), we need transparency and controllability during the process.

Based on these capabilities, I can implement an automated script to handle module-level software engineering tasks.

Taking Claude Code as an example:

1.  Claude Code can be invoked directly via CLI by passing a prompt to start a new session.
2.  When Claude Code outputs results to stdout using the `-p` parameter, it signals completion.
3.  Claude Code provides the ability to pass a session ID, allowing us to locate the corresponding conversation history file in the `.claude` directory and retrieve the historical messages.

Given this, I can write a script to manage this work.

Each session is independent and clean, and each session will be assigned to an Agent to complete.

An Agent instance can be abstracted as an interface, regardless of whether its underlying implementation is Claude Code or something else.

The scheduler will then coordinate different Agents to complete tasks according to our predefined workflow.

Why base it on an Agent rather than an LLM API? Because the Agent handles the underlying complexities of exploring the codebase, invoking operating system commands, managing context, and adapting to the LLM API. This is a complex system, and I believe we don't need to reinvent the wheel unless it doesn't meet our requirements.

I plan to first implement a minimal version to validate whether this approach is feasible. Stay tuned for subsequent progress updates.