---
title: 模块级人机协同软件工程架构
summary: 本文探讨了LLM在模块级人机协同软件工程中的局限性，如非强制性协调和有限算力，并提出了通过接口命名、单元测试和基准测试来减少人工介入的方法，旨在提升效率和降低成本。
tags:
  - 人机协同
  - 软件工程
  - LLM
  - AI Agent
  - 模块设计
  - 人工介入
  - 效率优化
inferred_lang: zh-Hans
---

# 模块级人机协同的软件工程架构

## 问题背景

设计一个 LLM 进行模块级别的人机协同工程架构，旨在高效率地完成工业级应用模块的设计、实现和迭代，减少人工介入成本。

1. 现有 AI Agent (Claude Code、CodeX) 对于代码模块的实现质量很差，仍然需要人类高度介入、返工、Review。
2. 现有 AI Agent 在实现过程中难以构造模块边界，导致编写出很多无用复杂度的代码。
3. 现有的 AI Agent 实现太慢，一个任务从发布到验收需要 10-30 分钟时间。

## 问题洞察

### 为什么 Agent 无法一次性完成所有工作？

因为 LLM 智能永远受限。

这有两个主要原因：（架构约束）非强制性协调、（资源约束）有限算力预算。一个次要的原因是（认知约束）认知不可压缩性。

**非强制性协调**：LLM 被强迫一定要说点什么，做点什么，但无法保证结果一定遵守约束。如果你假设 LLM 一定要回答，同时强制其遵守所有的约束。那么当你问出一个难解甚至无解的问题时，计算就会瘫痪。LLM 在底层设计中，选择了非强制性的协调，而是选择强制输出了概率最大的 Token。（停机问题）
一些困难的问题，是需要在复杂的关注点之间找到一个好的解决方案。LLM 的 Context 无法同时包含项目管理、设计、实现和验收，这是完全冲突的、对抗性的。只有关注点分离的架构才能避免 Agent 陷入困境。LLM 输出之前实际上没有被强制要求遵守所有的约束，因为那会造成思考崩溃。

**有限算力预算**：很显然，一个更聪明的 LLM 有能力兼顾更多的关注点，代价一定是更高的算力，所谓的 AGI 永远是不计代价条件下的天花板目标，而不是一个商用通用 LLM 的目标。而业务才能决定是否使用如此高的算力去解决问题，因此通用 LLM 无法自行决定这件事。此根本矛盾无法解决。（经济约束）
请注意明希豪森三难困境，思考本身的无限性与思考预算的有限性永远冲突。我们理想中希望 AI 成为一种神明般的存在，但实际上它永远只能是有限的智能，只因为它的思考需要消耗资源。

相对次要的原因：

**认知不可压缩性**：业务逻辑必须有足够的信息输入才能被解决。如果我们认为一句话可以给 LLM 讲清楚，这说明这个认知的传递是可以压缩的。实际上你需要补充很多上下文，LLM 才能知道所处的环境的复杂性。
为什么说这个是次要的原因，这个原因有一些挑战：即常识本身已经在 LLM 预训练中体现了，很多认知会随着 LLM 越来越强大，逐渐变成小问题。其次，LLM 可以先猜测补全，快速和人类进行对齐，这也减缓了矛盾。不过目前基于现状，还是有很大的问题。
相信很多资深 LLM 用户都能认识到这一点带来的问题。

但是，一个喜讯是，Agent 涌现的阈值是，Agent 至少能针对一个关注点产生有效输出，而这显然已经解锁。我们需要长期利用好有限的智能，作为工具，来完成我们的业务。

### 如何减少人工介入？

关键在于打消人类的顾虑，然后人就会出于“又不是不能用”的心态，不再进一步苛求 AI 的工作产出。

那么，什么检查通过之后，人会判断自己已经不具有能力介入，或者不必要采取更多措施？

1. 模块对外的接口概念命名品味符合需求。打消不合理的接口会蔓延到系统下游的顾虑。
2. 通过单元测试。打消这个模块是否能正常工作的顾虑。
3. 基准测试上有优化或者不劣化。打消这个模块是否效率很低的顾虑。
   第一点是在初始阶段就能发现的，而后面的需要等到实验结束才能得知。如果三者都满足了，人类没有什么理由去强行介入 AI 完成的工作。

至于此模块是否真正能应对真实数据模式，要使用生产环境数据来测试。然后由人总结其模式，通过意图构造一个新的模块，解决新的问题。这个问题暂时不在本文讨论范围之内。

### 优先级目标

1. 减少人工介入。
2. 减少运行时间，提升速度
3. 减少 Token 使用量，减少 LLM 费用。
